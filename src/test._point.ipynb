{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m \n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlist_physical_devices(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNum GPUs Available: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(tf\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mlist_physical_devices(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGPU\u001b[39m\u001b[38;5;124m'\u001b[39m)))\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
    "print(\"Tensorflow version: \"+tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 09:58:55.024548: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-02-06 09:58:55.024610: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-02-06 09:58:55.025859: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-02-06 09:58:55.032978: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-02-06 09:58:55.936261: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor Flow Version: 2.15.0\n",
      "\n",
      "Python 3.9.18 | packaged by conda-forge | (main, Dec 23 2023, 16:33:10) \n",
      "[GCC 12.3.0]\n",
      "GPU is NOT AVAILABLE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-02-06 09:58:56.789231: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-02-06 09:58:56.839935: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import tensorflow.keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(f\"Tensor Flow Version: {tf.__version__}\")\n",
    "print()\n",
    "print(f\"Python {sys.version}\")\n",
    "gpu = len(tf.config.list_physical_devices('GPU'))>0\n",
    "print(\"GPU is\", \"available\" if gpu else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.15.0.post1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow)\n",
      "  Using cached flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Collecting h5py>=2.9.0 (from tensorflow)\n",
      "  Using cached h5py-3.10.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.2.0 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting numpy<2.0.0,>=1.23.5 (from tensorflow)\n",
      "  Using cached numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "Requirement already satisfied: packaging in /home/faruk/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow) (23.2)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Using cached protobuf-4.25.2-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: setuptools in /home/faruk/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow) (68.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/faruk/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-2.4.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/faruk/miniconda3/envs/tf/lib/python3.9/site-packages (from tensorflow) (4.9.0)\n",
      "Collecting wrapt<1.15,>=1.11.0 (from tensorflow)\n",
      "  Using cached wrapt-1.14.1-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow)\n",
      "  Using cached tensorflow_io_gcs_filesystem-0.36.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.60.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.16,>=2.15 (from tensorflow)\n",
      "  Using cached tensorboard-2.15.1-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow)\n",
      "  Using cached tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.16,>=2.15.0 (from tensorflow)\n",
      "  Using cached keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/faruk/miniconda3/envs/tf/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow) (0.41.2)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Using cached google_auth-2.27.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting google-auth-oauthlib<2,>=0.5 (from tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Using cached google_auth_oauthlib-1.2.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Using cached Markdown-3.5.2-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow)\n",
      "  Using cached protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl.metadata (540 bytes)\n",
      "Collecting requests<3,>=2.21.0 (from tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Using cached requests-2.31.0-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Using cached werkzeug-3.0.1-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Using cached cachetools-5.3.2-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Using cached pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Using cached requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /home/faruk/miniconda3/envs/tf/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard<2.16,>=2.15->tensorflow) (7.0.1)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Using cached charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (33 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Using cached idna-3.6-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Using cached urllib3-2.2.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Using cached certifi-2024.2.2-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Downloading MarkupSafe-2.1.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /home/faruk/miniconda3/envs/tf/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.16,>=2.15->tensorflow) (3.17.0)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Using cached pyasn1-0.5.1-py2.py3-none-any.whl.metadata (8.6 kB)\n",
      "Collecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow)\n",
      "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
      "Using cached tensorflow-2.15.0.post1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
      "Using cached absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Using cached flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Using cached grpcio-1.60.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "Using cached h5py-3.10.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.8 MB)\n",
      "Using cached keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "Using cached libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "Using cached ml_dtypes-0.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "Using cached numpy-1.26.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
      "Using cached tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
      "Using cached protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
      "Using cached tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "Using cached tensorflow_io_gcs_filesystem-0.36.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "Using cached termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Using cached google_auth-2.27.0-py2.py3-none-any.whl (186 kB)\n",
      "Using cached google_auth_oauthlib-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "Using cached Markdown-3.5.2-py3-none-any.whl (103 kB)\n",
      "Using cached requests-2.31.0-py3-none-any.whl (62 kB)\n",
      "Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "Using cached werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "Using cached cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Using cached certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "Using cached charset_normalizer-3.3.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (142 kB)\n",
      "Using cached idna-3.6-py3-none-any.whl (61 kB)\n",
      "Downloading MarkupSafe-2.1.5-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
      "Using cached urllib3-2.2.0-py3-none-any.whl (120 kB)\n",
      "Using cached pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, urllib3, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, protobuf, oauthlib, numpy, MarkupSafe, keras, idna, grpcio, google-pasta, gast, charset-normalizer, certifi, cachetools, astunparse, absl-py, werkzeug, rsa, requests, pyasn1-modules, opt-einsum, ml-dtypes, markdown, h5py, requests-oauthlib, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed MarkupSafe-2.1.5 absl-py-2.1.0 astunparse-1.6.3 cachetools-5.3.2 certifi-2024.2.2 charset-normalizer-3.3.2 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.27.0 google-auth-oauthlib-1.2.0 google-pasta-0.2.0 grpcio-1.60.1 h5py-3.10.0 idna-3.6 keras-2.15.0 libclang-16.0.6 markdown-3.5.2 ml-dtypes-0.2.0 numpy-1.26.4 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-4.23.4 pyasn1-0.5.1 pyasn1-modules-0.3.0 requests-2.31.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.15.1 tensorboard-data-server-0.7.2 tensorflow-2.15.0.post1 tensorflow-estimator-2.15.0 tensorflow-io-gcs-filesystem-0.36.0 termcolor-2.4.0 urllib3-2.2.0 werkzeug-3.0.1 wrapt-1.14.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "from sklearn.utils import Bunch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from tensorflow import keras\n",
    "from keras.optimizers import SGD\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Conv1D\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getProfilSD(profil):\n",
    "    #Générer des données aléatoires pour le nuage de points\n",
    "    num_points = len(profil)\n",
    "    x_values = profil.x\n",
    "    y_values = profil.y\n",
    "\n",
    "    # # Créer le nuage de points\n",
    "    # plt.scatter(x_values, y_values, c='blue', marker='o', label='Nuage de points')\n",
    "\n",
    "    # Effectuer la régression linéaire\n",
    "    coefficients = np.polyfit(x_values, y_values, 1)\n",
    "    polynomial = np.poly1d(coefficients)\n",
    "\n",
    "    # Tracer la droite de régression linéaire\n",
    "    x_regression = np.linspace(min(x_values), max(x_values), num_points)\n",
    "\n",
    "    residuals = y_values -  polynomial(x_regression)\n",
    "    return np.std(residuals)\n",
    "                     \n",
    "def shiftYValues(profil):\n",
    "    zone1 = profil[(profil.x >= -570) & (profil.x <= -470)]\n",
    "    zone3 = profil[(profil.x >= 470) & (profil.x <= 570)]\n",
    "\n",
    "    sd_zone1 = getProfilSD(zone1) if not zone1.empty else None\n",
    "    sd_zone3 = getProfilSD(zone3) if not zone3.empty else None\n",
    "\n",
    "    if(sd_zone1 == None):\n",
    "        xmin = zone3.x.min()\n",
    "    elif(sd_zone3 == None):\n",
    "        xmin = zone1.x.min()\n",
    "    else : \n",
    "        xmin = zone3.x.min() if sd_zone3 < sd_zone1 else zone1.x.min()\n",
    "        \n",
    "    # print(f\"xmin : {xmin} ymin : {profil[profil.x == xmin].y.values[0]}\" )\n",
    "    profil['y'] -= profil.loc[profil['x'] == xmin, 'y'].values[0]\n",
    "    profil = profil[(profil.x >= -470) & (profil.x <= 470)]\n",
    "    return profil\n",
    "\n",
    "# Function to remove outlier from y \n",
    "def remove_outliers_from_y(points, min_threshold, max_threshold):\n",
    "    points.loc[(points.y >= max_threshold) | (points.y <= min_threshold), 'y'] = np.nan\n",
    "    # outlier_mask = points[(points.y >= max_threshold) | (points.y <= min_threshold)] \n",
    "    points.loc[:, 'y'] = points.loc[:, 'y'].ffill()\n",
    "    points.loc[:, 'y'] = points.loc[:, 'y'].bfill()\n",
    "    return points\n",
    "\n",
    "def process_normalization(profil, min, max):\n",
    "    profil['y'] = (profil.y - min) / (max - min)\n",
    "\n",
    "\n",
    "# Function to standardize the size of data by adding padding\n",
    "def pad_to_same_size(data):\n",
    "    # permet de mettre toutes les données à la même taille.     \n",
    "       \n",
    "    max_length = max(len(d) for d in data)\n",
    "    return [tf.pad(d, paddings=[[0, max_length - len(d)]], mode='SYMMETRIC') if len(d) < max_length else d for d in data]\n",
    "\n",
    "# Function to process each CSV file\n",
    "def process_csv_file(file_path):\n",
    "    min_y = -110\n",
    "    max_y = 200 \n",
    "    points = pd.read_csv(file_path, names=['x', 'y'])\n",
    "    sorted_points = points.sort_values(by='x')\n",
    "    sorted_points = sorted_points.drop_duplicates()\n",
    "    # shifted_points = shiftYValues(sorted_points)\n",
    "    # cleaned_points = remove_outliers_from_y(shifted_points,min_y,max_y)\n",
    "    sorted_points = sorted_points[(sorted_points.x >= -470) & (sorted_points.x <= 470)]\n",
    "    # sorted_points.y +=1200\n",
    "    # sorted_points.y /=10\n",
    "    \n",
    "    # process_normalization(cleaned_points,min_y,max_y)\n",
    "    return sorted_points.y\n",
    "\n",
    "def load_profiles(src):\n",
    "    classes_id = [d for d in os.listdir(src) if os.path.isdir(os.path.join(src, d))]\n",
    "    data = []\n",
    "    target = []\n",
    "    for classe_id in classes_id:\n",
    "        dataset_path = os.path.join(src,classe_id)\n",
    "        files_path = [os.path.join(dataset_path, file) for file in os.listdir(dataset_path) if file.endswith('.csv')]\n",
    "        for file_path  in files_path: \n",
    "            profil_points = process_csv_file(file_path)\n",
    "            data.append(profil_points)\n",
    "            target.append(classe_id)\n",
    "    \n",
    "    padded_data = pad_to_same_size(data)\n",
    "    return  Bunch(\n",
    "         data= np.array(padded_data), \n",
    "         target= np.array(target) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = \"C:\\\\Users\\\\onerf\\\\Documents\\\\UMons\\\\Master2\\\\Stage\\\\ballast\\\\ballast-toolbox\\\\src\\\\main\\\\resources\\\\template-export\\\\\"\n",
    "profiles = load_profiles(dataset_root + \"sleepers_db\\\\\")\n",
    "profiles_test = load_profiles(dataset_root + \"test\\\\\")\n",
    "\n",
    "id2int = {v:ix for ix,v in enumerate(np.unique(profiles.target))}\n",
    "int2id = {v:ix for ix,v in enumerate(np.unique(profiles.target))}\n",
    "\n",
    "profiles.target = [id2int[val] for val in profiles.target]\n",
    "profiles_test.target = [id2int[val] for val in profiles_test.target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape : (2220, 437, 1)\n",
      "x_test shape : (400, 437, 1)\n"
     ]
    }
   ],
   "source": [
    "x, y = profiles.data, profiles.target\n",
    "x = x.reshape(x.shape[0],x.shape[1],1)\n",
    "print(f'x shape : {x.shape}')\n",
    "x_test, y_test = profiles_test.data, profiles_test.target\n",
    "x_test= x_test.reshape(x_test.shape[0],x_test.shape[1],1)\n",
    "print(f'x_test shape : {x_test.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(keras.layers.Conv1D(16,8, activation='relu', input_shape=(437, 1)))\n",
    "    # model.add(keras.layers.Conv1D(16,8, activation='relu', input_shape=(437, 1)))\n",
    "    model.add(Flatten())  # Flatten the output from the convolutional layer\n",
    "    # model.add(keras.layers.Dense(units=256, activation='sigmoid'))  # Assuming 3 classes, adjust based on your task\n",
    "    model.add(keras.layers.Dense(units=3, activation='softmax'))  # Assuming 3 classes, adjust based on your task\n",
    "    return model\n",
    "\n",
    "# batch_size=4 #@param [1,2,4,8,16,32,64,128] {type:\"raw\"}\n",
    "# epochs=5 #@param [5, 10,20,50,100,200] {type:\"raw\"}\n",
    "\n",
    "# model = get_model()\n",
    "# model.compile(optimizer=SGD(learning_rate=0.01), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "# history = model.fit(x, y, epochs=epochs, validation_split=0.2, shuffle=True, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 61570.2422 - accuracy: 0.4262 - val_loss: 1.5980 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0136 - accuracy: 0.4240 - val_loss: 1.7987 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0100 - accuracy: 0.4178 - val_loss: 1.8726 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4172 - val_loss: 1.8970 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4122 - val_loss: 1.9078 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.2464 - accuracy: 0.3150\n",
      "Epoch 1/10\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 6168.2939 - accuracy: 0.4257 - val_loss: 1.6041 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0136 - accuracy: 0.4071 - val_loss: 1.7960 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0098 - accuracy: 0.4245 - val_loss: 1.8656 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0096 - accuracy: 0.4133 - val_loss: 1.8854 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4172 - val_loss: 1.9073 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4285 - val_loss: 1.9183 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4307 - val_loss: 1.9198 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4155 - val_loss: 1.9046 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4251 - val_loss: 1.9109 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4172 - val_loss: 1.9126 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2477 - accuracy: 0.3150\n",
      "Epoch 1/20\n",
      "444/444 [==============================] - 2s 3ms/step - loss: 40766.5664 - accuracy: 0.4217 - val_loss: 1.6079 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0133 - accuracy: 0.4257 - val_loss: 1.7937 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0098 - accuracy: 0.4245 - val_loss: 1.8731 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4274 - val_loss: 1.9071 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4150 - val_loss: 1.9205 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4217 - val_loss: 1.9094 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0092 - accuracy: 0.4291 - val_loss: 1.8990 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "444/444 [==============================] - 2s 3ms/step - loss: 1.0093 - accuracy: 0.4279 - val_loss: 1.9207 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4251 - val_loss: 1.9213 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0091 - accuracy: 0.4245 - val_loss: 1.9249 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4206 - val_loss: 1.9206 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4217 - val_loss: 1.9354 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4262 - val_loss: 1.9355 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4167 - val_loss: 1.9335 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4217 - val_loss: 1.9274 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4200 - val_loss: 1.9173 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0092 - accuracy: 0.4336 - val_loss: 1.9139 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4167 - val_loss: 1.9044 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4122 - val_loss: 1.9165 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4229 - val_loss: 1.9218 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.2501 - accuracy: 0.3150\n",
      "Epoch 1/50\n",
      "444/444 [==============================] - 2s 4ms/step - loss: 53870.4102 - accuracy: 0.4178 - val_loss: 1.6109 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0136 - accuracy: 0.4200 - val_loss: 1.7906 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0101 - accuracy: 0.4178 - val_loss: 1.8524 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4178 - val_loss: 1.8957 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4054 - val_loss: 1.9042 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4212 - val_loss: 1.9195 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4003 - val_loss: 1.9115 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0092 - accuracy: 0.4240 - val_loss: 1.9241 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4178 - val_loss: 1.9162 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4189 - val_loss: 1.9179 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4291 - val_loss: 1.9157 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4088 - val_loss: 1.9228 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "444/444 [==============================] - 2s 4ms/step - loss: 1.0093 - accuracy: 0.4257 - val_loss: 1.9116 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "444/444 [==============================] - 2s 4ms/step - loss: 1.0093 - accuracy: 0.4189 - val_loss: 1.9223 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "444/444 [==============================] - 2s 4ms/step - loss: 1.0094 - accuracy: 0.4274 - val_loss: 1.9232 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4268 - val_loss: 1.9290 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4122 - val_loss: 1.9109 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4240 - val_loss: 1.9164 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4291 - val_loss: 1.9116 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4285 - val_loss: 1.9175 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4279 - val_loss: 1.9157 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4262 - val_loss: 1.9172 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4099 - val_loss: 1.9101 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4088 - val_loss: 1.9041 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4229 - val_loss: 1.9187 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "444/444 [==============================] - 2s 4ms/step - loss: 1.0093 - accuracy: 0.4127 - val_loss: 1.9262 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "444/444 [==============================] - 2s 3ms/step - loss: 1.0092 - accuracy: 0.4037 - val_loss: 1.9133 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "444/444 [==============================] - 2s 5ms/step - loss: 1.0093 - accuracy: 0.4251 - val_loss: 1.9001 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "444/444 [==============================] - 2s 4ms/step - loss: 1.0093 - accuracy: 0.4200 - val_loss: 1.9005 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4262 - val_loss: 1.9046 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "444/444 [==============================] - 2s 4ms/step - loss: 1.0093 - accuracy: 0.4212 - val_loss: 1.8994 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "444/444 [==============================] - 2s 4ms/step - loss: 1.0093 - accuracy: 0.4167 - val_loss: 1.9138 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4296 - val_loss: 1.9261 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.3998 - val_loss: 1.9225 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4184 - val_loss: 1.9198 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4240 - val_loss: 1.9280 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0092 - accuracy: 0.4324 - val_loss: 1.9340 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4240 - val_loss: 1.9352 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4161 - val_loss: 1.9278 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0092 - accuracy: 0.4245 - val_loss: 1.9330 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0092 - accuracy: 0.4302 - val_loss: 1.9306 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0092 - accuracy: 0.4172 - val_loss: 1.9103 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4217 - val_loss: 1.9202 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4093 - val_loss: 1.9053 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0092 - accuracy: 0.4302 - val_loss: 1.9103 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4161 - val_loss: 1.9085 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0092 - accuracy: 0.4313 - val_loss: 1.9094 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0092 - accuracy: 0.4262 - val_loss: 1.9224 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4229 - val_loss: 1.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4251 - val_loss: 1.9173 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.2489 - accuracy: 0.3150\n",
      "Epoch 1/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 240457.6719 - accuracy: 0.4184 - val_loss: 1.6133 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0136 - accuracy: 0.4217 - val_loss: 1.7868 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0101 - accuracy: 0.4251 - val_loss: 1.8560 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4319 - val_loss: 1.8847 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0092 - accuracy: 0.4313 - val_loss: 1.9111 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4217 - val_loss: 1.9215 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0092 - accuracy: 0.4296 - val_loss: 1.9321 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0092 - accuracy: 0.4302 - val_loss: 1.9255 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4105 - val_loss: 1.9176 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4291 - val_loss: 1.9112 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0090 - accuracy: 0.4375 - val_loss: 1.9194 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4223 - val_loss: 1.9130 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4195 - val_loss: 1.9197 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4223 - val_loss: 1.9075 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4099 - val_loss: 1.9129 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4167 - val_loss: 1.9176 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4178 - val_loss: 1.9126 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0091 - accuracy: 0.4307 - val_loss: 1.9281 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4223 - val_loss: 1.9249 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0092 - accuracy: 0.4133 - val_loss: 1.9193 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4043 - val_loss: 1.9257 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4150 - val_loss: 1.9274 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4184 - val_loss: 1.9148 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0092 - accuracy: 0.4144 - val_loss: 1.9319 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4099 - val_loss: 1.9319 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4285 - val_loss: 1.9180 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "444/444 [==============================] - 2s 4ms/step - loss: 1.0093 - accuracy: 0.4172 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4150 - val_loss: 1.9266 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4217 - val_loss: 1.9304 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4251 - val_loss: 1.9187 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4200 - val_loss: 1.9161 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4127 - val_loss: 1.9160 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4251 - val_loss: 1.9177 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "444/444 [==============================] - 2s 4ms/step - loss: 1.0093 - accuracy: 0.4200 - val_loss: 1.9103 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4133 - val_loss: 1.9126 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4302 - val_loss: 1.9123 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4223 - val_loss: 1.9218 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4229 - val_loss: 1.9223 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4257 - val_loss: 1.9098 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "444/444 [==============================] - 2s 3ms/step - loss: 1.0094 - accuracy: 0.4065 - val_loss: 1.9102 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4251 - val_loss: 1.9190 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4307 - val_loss: 1.9174 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4099 - val_loss: 1.9075 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4307 - val_loss: 1.9167 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4172 - val_loss: 1.9150 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4178 - val_loss: 1.9102 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4257 - val_loss: 1.9041 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4223 - val_loss: 1.9034 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "444/444 [==============================] - 2s 4ms/step - loss: 1.0094 - accuracy: 0.4212 - val_loss: 1.8994 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4139 - val_loss: 1.8979 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4296 - val_loss: 1.9122 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4032 - val_loss: 1.9083 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4195 - val_loss: 1.9152 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4234 - val_loss: 1.9073 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4122 - val_loss: 1.9225 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4150 - val_loss: 1.9238 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4054 - val_loss: 1.9216 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4251 - val_loss: 1.9165 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4105 - val_loss: 1.9236 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4155 - val_loss: 1.9195 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0092 - accuracy: 0.4307 - val_loss: 1.9234 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4122 - val_loss: 1.9073 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4155 - val_loss: 1.9251 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4217 - val_loss: 1.9191 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0092 - accuracy: 0.4206 - val_loss: 1.9192 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4257 - val_loss: 1.9218 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4212 - val_loss: 1.9281 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4077 - val_loss: 1.9107 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4122 - val_loss: 1.9008 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0092 - accuracy: 0.4302 - val_loss: 1.9115 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4167 - val_loss: 1.9223 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4240 - val_loss: 1.9224 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4229 - val_loss: 1.9224 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4245 - val_loss: 1.9101 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4155 - val_loss: 1.9115 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4178 - val_loss: 1.9122 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4234 - val_loss: 1.9117 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4279 - val_loss: 1.9208 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4195 - val_loss: 1.9294 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4099 - val_loss: 1.9246 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0092 - accuracy: 0.4223 - val_loss: 1.9188 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4212 - val_loss: 1.9246 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4240 - val_loss: 1.9371 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4105 - val_loss: 1.9286 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4110 - val_loss: 1.9220 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4093 - val_loss: 1.9073 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4150 - val_loss: 1.9082 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4257 - val_loss: 1.9080 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4184 - val_loss: 1.9078 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0092 - accuracy: 0.4212 - val_loss: 1.8984 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4217 - val_loss: 1.9055 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4167 - val_loss: 1.9185 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4217 - val_loss: 1.8935 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4251 - val_loss: 1.9086 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4375 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4200 - val_loss: 1.9055 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0092 - accuracy: 0.4217 - val_loss: 1.9138 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4139 - val_loss: 1.9231 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "444/444 [==============================] - 2s 4ms/step - loss: 1.0094 - accuracy: 0.4122 - val_loss: 1.9241 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4212 - val_loss: 1.9157 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2485 - accuracy: 0.3125\n",
      "Epoch 1/200\n",
      "444/444 [==============================] - 2s 4ms/step - loss: 274484.6875 - accuracy: 0.4223 - val_loss: 1.6009 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0137 - accuracy: 0.4155 - val_loss: 1.7878 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0101 - accuracy: 0.4212 - val_loss: 1.8454 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4313 - val_loss: 1.8906 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4262 - val_loss: 1.9274 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4245 - val_loss: 1.9267 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4223 - val_loss: 1.9081 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0092 - accuracy: 0.4200 - val_loss: 1.9201 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4229 - val_loss: 1.9135 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4139 - val_loss: 1.9381 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0095 - accuracy: 0.4178 - val_loss: 1.9357 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "444/444 [==============================] - 2s 3ms/step - loss: 1.0092 - accuracy: 0.4302 - val_loss: 1.9198 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "444/444 [==============================] - 2s 4ms/step - loss: 1.0093 - accuracy: 0.4150 - val_loss: 1.9231 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4313 - val_loss: 1.9054 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0090 - accuracy: 0.4341 - val_loss: 1.9042 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4150 - val_loss: 1.9162 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4099 - val_loss: 1.9146 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4279 - val_loss: 1.9182 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4251 - val_loss: 1.9173 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/200\n",
      "444/444 [==============================] - 2s 4ms/step - loss: 1.0094 - accuracy: 0.4200 - val_loss: 1.9175 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4262 - val_loss: 1.9158 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4296 - val_loss: 1.9288 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0091 - accuracy: 0.4268 - val_loss: 1.9397 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4217 - val_loss: 1.9312 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4167 - val_loss: 1.9306 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4212 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4116 - val_loss: 1.9221 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4116 - val_loss: 1.9139 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4274 - val_loss: 1.9229 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4313 - val_loss: 1.9124 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4234 - val_loss: 1.9068 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4150 - val_loss: 1.9127 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4229 - val_loss: 1.9184 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4200 - val_loss: 1.9133 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0092 - accuracy: 0.4257 - val_loss: 1.9096 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4296 - val_loss: 1.9069 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0092 - accuracy: 0.4257 - val_loss: 1.9105 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4223 - val_loss: 1.9168 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.3981 - val_loss: 1.9002 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4105 - val_loss: 1.9131 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4071 - val_loss: 1.9277 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4245 - val_loss: 1.9132 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4088 - val_loss: 1.9185 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4240 - val_loss: 1.9185 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/200\n",
      "444/444 [==============================] - 2s 4ms/step - loss: 1.0094 - accuracy: 0.4167 - val_loss: 1.9119 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4251 - val_loss: 1.9179 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4347 - val_loss: 1.9273 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4167 - val_loss: 1.9238 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4251 - val_loss: 1.9163 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4200 - val_loss: 1.9049 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4105 - val_loss: 1.9288 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4279 - val_loss: 1.9132 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4110 - val_loss: 1.9288 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/200\n",
      "444/444 [==============================] - 2s 3ms/step - loss: 1.0093 - accuracy: 0.4195 - val_loss: 1.9162 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4274 - val_loss: 1.9158 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4189 - val_loss: 1.9347 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/200\n",
      "444/444 [==============================] - 2s 4ms/step - loss: 1.0094 - accuracy: 0.4065 - val_loss: 1.9295 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/200\n",
      "444/444 [==============================] - 2s 4ms/step - loss: 1.0093 - accuracy: 0.4099 - val_loss: 1.9133 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/200\n",
      "444/444 [==============================] - 2s 5ms/step - loss: 1.0092 - accuracy: 0.4127 - val_loss: 1.9018 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/200\n",
      "444/444 [==============================] - 2s 4ms/step - loss: 1.0093 - accuracy: 0.4296 - val_loss: 1.9206 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/200\n",
      "444/444 [==============================] - 2s 5ms/step - loss: 1.0093 - accuracy: 0.4223 - val_loss: 1.9055 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4240 - val_loss: 1.9122 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4245 - val_loss: 1.9054 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/200\n",
      "444/444 [==============================] - 2s 4ms/step - loss: 1.0092 - accuracy: 0.4217 - val_loss: 1.9013 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/200\n",
      "444/444 [==============================] - 2s 4ms/step - loss: 1.0093 - accuracy: 0.4155 - val_loss: 1.9091 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4172 - val_loss: 1.9035 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4206 - val_loss: 1.9108 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4144 - val_loss: 1.9091 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4240 - val_loss: 1.9162 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4217 - val_loss: 1.9203 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4212 - val_loss: 1.9085 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4116 - val_loss: 1.9278 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4150 - val_loss: 1.9133 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/200\n",
      "444/444 [==============================] - 2s 4ms/step - loss: 1.0093 - accuracy: 0.4127 - val_loss: 1.9182 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4144 - val_loss: 1.9203 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4082 - val_loss: 1.9073 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4133 - val_loss: 1.9242 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4195 - val_loss: 1.9351 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4200 - val_loss: 1.9223 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4257 - val_loss: 1.9291 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4122 - val_loss: 1.9241 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4229 - val_loss: 1.9216 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4082 - val_loss: 1.9225 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4071 - val_loss: 1.9222 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4139 - val_loss: 1.9171 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4139 - val_loss: 1.9090 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4150 - val_loss: 1.9081 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0092 - accuracy: 0.4212 - val_loss: 1.9314 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0092 - accuracy: 0.4358 - val_loss: 1.9315 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0092 - accuracy: 0.4245 - val_loss: 1.9317 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4184 - val_loss: 1.9218 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4229 - val_loss: 1.9274 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4077 - val_loss: 1.9309 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4296 - val_loss: 1.9232 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4279 - val_loss: 1.9111 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4291 - val_loss: 1.8934 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4184 - val_loss: 1.9171 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4324 - val_loss: 1.9200 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4184 - val_loss: 1.9181 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4234 - val_loss: 1.9263 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4144 - val_loss: 1.9173 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4364 - val_loss: 1.9150 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4105 - val_loss: 1.9257 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/200\n",
      "444/444 [==============================] - 2s 3ms/step - loss: 1.0094 - accuracy: 0.4105 - val_loss: 1.9215 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4116 - val_loss: 1.9137 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4178 - val_loss: 1.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4296 - val_loss: 1.9217 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4251 - val_loss: 1.9293 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4167 - val_loss: 1.9134 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0095 - accuracy: 0.4212 - val_loss: 1.9192 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4184 - val_loss: 1.9203 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0092 - accuracy: 0.4150 - val_loss: 1.9155 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4291 - val_loss: 1.9257 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0090 - accuracy: 0.4291 - val_loss: 1.9256 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4285 - val_loss: 1.9315 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4302 - val_loss: 1.9202 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0089 - accuracy: 0.4364 - val_loss: 1.9300 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4257 - val_loss: 1.9254 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4099 - val_loss: 1.9071 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0088 - accuracy: 0.4369 - val_loss: 1.9285 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4234 - val_loss: 1.9266 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4200 - val_loss: 1.9210 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4217 - val_loss: 1.9102 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4054 - val_loss: 1.9255 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4285 - val_loss: 1.9268 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4274 - val_loss: 1.9250 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4229 - val_loss: 1.9227 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4167 - val_loss: 1.9161 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4251 - val_loss: 1.9211 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0091 - accuracy: 0.4285 - val_loss: 1.9299 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4291 - val_loss: 1.9305 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4161 - val_loss: 1.9127 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4195 - val_loss: 1.9209 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4139 - val_loss: 1.9264 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4234 - val_loss: 1.9189 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4144 - val_loss: 1.9226 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4358 - val_loss: 1.9158 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4279 - val_loss: 1.9226 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4324 - val_loss: 1.9046 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4262 - val_loss: 1.9138 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4150 - val_loss: 1.9288 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4285 - val_loss: 1.9167 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4223 - val_loss: 1.9213 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4155 - val_loss: 1.9188 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4234 - val_loss: 1.9217 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4150 - val_loss: 1.9073 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4172 - val_loss: 1.9168 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4336 - val_loss: 1.9278 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4274 - val_loss: 1.9236 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4291 - val_loss: 1.9295 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4060 - val_loss: 1.9168 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4251 - val_loss: 1.9314 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4184 - val_loss: 1.9286 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0095 - accuracy: 0.4077 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4172 - val_loss: 1.9282 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4302 - val_loss: 1.9173 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4032 - val_loss: 1.9184 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0092 - accuracy: 0.4274 - val_loss: 1.9091 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4217 - val_loss: 1.9132 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4155 - val_loss: 1.9204 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4133 - val_loss: 1.9215 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0092 - accuracy: 0.4200 - val_loss: 1.9255 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4167 - val_loss: 1.9244 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4200 - val_loss: 1.9236 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4116 - val_loss: 1.9052 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4122 - val_loss: 1.9046 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4178 - val_loss: 1.9052 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4206 - val_loss: 1.9147 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4127 - val_loss: 1.9255 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.3986 - val_loss: 1.9225 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0090 - accuracy: 0.4307 - val_loss: 1.9363 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4139 - val_loss: 1.9245 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4133 - val_loss: 1.9225 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0094 - accuracy: 0.4200 - val_loss: 1.9313 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4212 - val_loss: 1.9185 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4110 - val_loss: 1.9146 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4251 - val_loss: 1.9097 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4167 - val_loss: 1.9106 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4071 - val_loss: 1.9108 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4268 - val_loss: 1.9157 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4364 - val_loss: 1.9190 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4155 - val_loss: 1.9256 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4217 - val_loss: 1.9128 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/200\n",
      "444/444 [==============================] - 2s 3ms/step - loss: 1.0093 - accuracy: 0.4268 - val_loss: 1.9228 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/200\n",
      "444/444 [==============================] - 2s 4ms/step - loss: 1.0093 - accuracy: 0.4133 - val_loss: 1.9165 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4155 - val_loss: 1.9024 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4150 - val_loss: 1.9118 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4229 - val_loss: 1.9024 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4313 - val_loss: 1.9040 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4133 - val_loss: 1.8989 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4291 - val_loss: 1.9153 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/200\n",
      "444/444 [==============================] - 1s 2ms/step - loss: 1.0093 - accuracy: 0.4206 - val_loss: 1.9281 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/200\n",
      "444/444 [==============================] - 2s 4ms/step - loss: 1.0090 - accuracy: 0.4251 - val_loss: 1.9394 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4217 - val_loss: 1.9443 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4240 - val_loss: 1.9323 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4245 - val_loss: 1.9286 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4313 - val_loss: 1.9283 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4296 - val_loss: 1.9251 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4161 - val_loss: 1.9227 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/200\n",
      "444/444 [==============================] - 1s 3ms/step - loss: 1.0093 - accuracy: 0.4155 - val_loss: 1.9143 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2481 - accuracy: 0.3150\n",
      "Epoch 1/5\n",
      "222/222 [==============================] - 2s 5ms/step - loss: 409042.5000 - accuracy: 0.3981 - val_loss: 1.4141 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0261 - accuracy: 0.4268 - val_loss: 1.6068 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0152 - accuracy: 0.4206 - val_loss: 1.7209 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0114 - accuracy: 0.4268 - val_loss: 1.7887 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0100 - accuracy: 0.4296 - val_loss: 1.8313 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2267 - accuracy: 0.3150\n",
      "Epoch 1/10\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 128977.3516 - accuracy: 0.4071 - val_loss: 1.4168 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0262 - accuracy: 0.4285 - val_loss: 1.6033 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0152 - accuracy: 0.4178 - val_loss: 1.7231 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0113 - accuracy: 0.4291 - val_loss: 1.7892 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0100 - accuracy: 0.4296 - val_loss: 1.8323 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0095 - accuracy: 0.4234 - val_loss: 1.8633 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4223 - val_loss: 1.8825 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4223 - val_loss: 1.8953 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4178 - val_loss: 1.9037 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4262 - val_loss: 1.9112 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2473 - accuracy: 0.3150\n",
      "Epoch 1/20\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 73446.0547 - accuracy: 0.4240 - val_loss: 1.4135 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0262 - accuracy: 0.4229 - val_loss: 1.6056 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0152 - accuracy: 0.4296 - val_loss: 1.7189 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0114 - accuracy: 0.4229 - val_loss: 1.7940 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 1.0099 - accuracy: 0.4245 - val_loss: 1.8380 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 1.0094 - accuracy: 0.4195 - val_loss: 1.8639 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0092 - accuracy: 0.4184 - val_loss: 1.8869 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0091 - accuracy: 0.4296 - val_loss: 1.8967 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4307 - val_loss: 1.9044 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4229 - val_loss: 1.9073 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4274 - val_loss: 1.9106 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4161 - val_loss: 1.9130 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4054 - val_loss: 1.9133 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0089 - accuracy: 0.4223 - val_loss: 1.9137 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4223 - val_loss: 1.9158 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4234 - val_loss: 1.9189 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4206 - val_loss: 1.9125 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4212 - val_loss: 1.9156 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4223 - val_loss: 1.9177 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0091 - accuracy: 0.4161 - val_loss: 1.9190 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2494 - accuracy: 0.3150\n",
      "Epoch 1/50\n",
      "222/222 [==============================] - 2s 5ms/step - loss: 117154.6094 - accuracy: 0.4122 - val_loss: 1.4159 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0261 - accuracy: 0.4110 - val_loss: 1.6060 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0152 - accuracy: 0.4296 - val_loss: 1.7198 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0114 - accuracy: 0.4274 - val_loss: 1.7930 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0100 - accuracy: 0.4279 - val_loss: 1.8351 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4279 - val_loss: 1.8648 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4296 - val_loss: 1.8864 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4223 - val_loss: 1.8985 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0089 - accuracy: 0.4302 - val_loss: 1.9079 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4077 - val_loss: 1.9122 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4172 - val_loss: 1.9157 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0089 - accuracy: 0.4336 - val_loss: 1.9176 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4212 - val_loss: 1.9232 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 1.0090 - accuracy: 0.4217 - val_loss: 1.9235 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4206 - val_loss: 1.9172 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4184 - val_loss: 1.9174 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4077 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4245 - val_loss: 1.9149 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4110 - val_loss: 1.9176 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4251 - val_loss: 1.9214 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4223 - val_loss: 1.9167 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4223 - val_loss: 1.9148 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.9134 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4245 - val_loss: 1.9174 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4212 - val_loss: 1.9153 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4212 - val_loss: 1.9156 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4088 - val_loss: 1.9175 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4240 - val_loss: 1.9154 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0089 - accuracy: 0.4274 - val_loss: 1.9207 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4155 - val_loss: 1.9211 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4161 - val_loss: 1.9198 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4229 - val_loss: 1.9167 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0089 - accuracy: 0.4251 - val_loss: 1.9197 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4245 - val_loss: 1.9254 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4285 - val_loss: 1.9210 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4144 - val_loss: 1.9227 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.9197 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 1.0090 - accuracy: 0.4279 - val_loss: 1.9195 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4206 - val_loss: 1.9224 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4093 - val_loss: 1.9164 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4229 - val_loss: 1.9179 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.9196 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 1.0090 - accuracy: 0.4223 - val_loss: 1.9133 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0088 - accuracy: 0.4313 - val_loss: 1.9145 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4296 - val_loss: 1.9145 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4251 - val_loss: 1.9168 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4285 - val_loss: 1.9096 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4223 - val_loss: 1.9129 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4251 - val_loss: 1.9114 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4234 - val_loss: 1.9108 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.2472 - accuracy: 0.3150\n",
      "Epoch 1/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 679673.8750 - accuracy: 0.4229 - val_loss: 1.4093 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0264 - accuracy: 0.4240 - val_loss: 1.6042 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0153 - accuracy: 0.4206 - val_loss: 1.7173 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0115 - accuracy: 0.4240 - val_loss: 1.7908 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0100 - accuracy: 0.4195 - val_loss: 1.8338 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0095 - accuracy: 0.4184 - val_loss: 1.8632 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4296 - val_loss: 1.8816 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4251 - val_loss: 1.8958 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4116 - val_loss: 1.9011 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4262 - val_loss: 1.9106 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9097 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4099 - val_loss: 1.9121 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4200 - val_loss: 1.9133 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4167 - val_loss: 1.9132 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4257 - val_loss: 1.9168 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4217 - val_loss: 1.9199 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4307 - val_loss: 1.9159 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4161 - val_loss: 1.9166 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4167 - val_loss: 1.9180 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0089 - accuracy: 0.4313 - val_loss: 1.9190 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4234 - val_loss: 1.9209 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4071 - val_loss: 1.9204 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4268 - val_loss: 1.9222 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4274 - val_loss: 1.9205 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4285 - val_loss: 1.9174 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4217 - val_loss: 1.9181 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0089 - accuracy: 0.4268 - val_loss: 1.9152 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0089 - accuracy: 0.4274 - val_loss: 1.9162 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4155 - val_loss: 1.9158 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4274 - val_loss: 1.9184 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4184 - val_loss: 1.9185 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4093 - val_loss: 1.9172 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4161 - val_loss: 1.9200 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.9140 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4245 - val_loss: 1.9127 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4110 - val_loss: 1.9129 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0089 - accuracy: 0.4313 - val_loss: 1.9130 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4026 - val_loss: 1.9174 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4223 - val_loss: 1.9152 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0091 - accuracy: 0.4206 - val_loss: 1.9147 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4178 - val_loss: 1.9191 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4144 - val_loss: 1.9229 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.9206 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 1.0090 - accuracy: 0.4144 - val_loss: 1.9206 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4206 - val_loss: 1.9179 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0091 - accuracy: 0.4274 - val_loss: 1.9165 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4268 - val_loss: 1.9177 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4144 - val_loss: 1.9160 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4268 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.9198 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0089 - accuracy: 0.4240 - val_loss: 1.9201 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4279 - val_loss: 1.9201 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4093 - val_loss: 1.9206 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0089 - accuracy: 0.4229 - val_loss: 1.9199 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4200 - val_loss: 1.9202 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4274 - val_loss: 1.9213 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4116 - val_loss: 1.9235 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4178 - val_loss: 1.9210 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4195 - val_loss: 1.9211 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4212 - val_loss: 1.9162 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4189 - val_loss: 1.9145 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4127 - val_loss: 1.9146 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4043 - val_loss: 1.9158 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.9172 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4189 - val_loss: 1.9202 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4200 - val_loss: 1.9192 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4200 - val_loss: 1.9190 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4240 - val_loss: 1.9192 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4268 - val_loss: 1.9220 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4178 - val_loss: 1.9261 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4262 - val_loss: 1.9238 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4268 - val_loss: 1.9225 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.9213 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4082 - val_loss: 1.9208 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4279 - val_loss: 1.9188 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4245 - val_loss: 1.9190 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4178 - val_loss: 1.9163 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4245 - val_loss: 1.9215 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4212 - val_loss: 1.9222 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4240 - val_loss: 1.9184 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4082 - val_loss: 1.9190 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4251 - val_loss: 1.9205 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4279 - val_loss: 1.9181 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4184 - val_loss: 1.9164 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4178 - val_loss: 1.9210 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4291 - val_loss: 1.9241 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.9224 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4217 - val_loss: 1.9179 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4127 - val_loss: 1.9175 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4223 - val_loss: 1.9184 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4088 - val_loss: 1.9187 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4229 - val_loss: 1.9197 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4110 - val_loss: 1.9234 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4279 - val_loss: 1.9258 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4212 - val_loss: 1.9204 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4234 - val_loss: 1.9209 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4195 - val_loss: 1.9198 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4285 - val_loss: 1.9179 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4178 - val_loss: 1.9186 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.2493 - accuracy: 0.3150\n",
      "Epoch 1/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 384789.5938 - accuracy: 0.4189 - val_loss: 1.4204 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0260 - accuracy: 0.4088 - val_loss: 1.6059 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0153 - accuracy: 0.4139 - val_loss: 1.7193 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0114 - accuracy: 0.4285 - val_loss: 1.7914 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0100 - accuracy: 0.4172 - val_loss: 1.8317 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0094 - accuracy: 0.4139 - val_loss: 1.8616 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0092 - accuracy: 0.4296 - val_loss: 1.8824 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4206 - val_loss: 1.8954 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4279 - val_loss: 1.9009 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4245 - val_loss: 1.9041 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4330 - val_loss: 1.9067 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4212 - val_loss: 1.9134 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4195 - val_loss: 1.9114 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4268 - val_loss: 1.9114 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4330 - val_loss: 1.9140 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.9180 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4099 - val_loss: 1.9188 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4274 - val_loss: 1.9208 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.9221 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4262 - val_loss: 1.9200 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4234 - val_loss: 1.9215 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4234 - val_loss: 1.9189 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4268 - val_loss: 1.9195 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4274 - val_loss: 1.9168 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4139 - val_loss: 1.9152 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4189 - val_loss: 1.9138 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.9113 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4178 - val_loss: 1.9148 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4245 - val_loss: 1.9161 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4189 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.9193 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0089 - accuracy: 0.4251 - val_loss: 1.9133 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4223 - val_loss: 1.9134 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4245 - val_loss: 1.9150 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4139 - val_loss: 1.9165 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4223 - val_loss: 1.9182 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4116 - val_loss: 1.9168 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4184 - val_loss: 1.9181 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.9193 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4251 - val_loss: 1.9167 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4212 - val_loss: 1.9222 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0089 - accuracy: 0.4302 - val_loss: 1.9230 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4093 - val_loss: 1.9224 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4234 - val_loss: 1.9205 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.9224 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4122 - val_loss: 1.9182 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4200 - val_loss: 1.9152 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4229 - val_loss: 1.9138 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4257 - val_loss: 1.9141 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4268 - val_loss: 1.9124 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4245 - val_loss: 1.9114 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4189 - val_loss: 1.9132 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4060 - val_loss: 1.9139 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4144 - val_loss: 1.9156 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4229 - val_loss: 1.9216 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4262 - val_loss: 1.9202 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0089 - accuracy: 0.4324 - val_loss: 1.9191 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.9199 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.9204 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4234 - val_loss: 1.9205 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4195 - val_loss: 1.9213 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4122 - val_loss: 1.9203 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0088 - accuracy: 0.4285 - val_loss: 1.9203 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4054 - val_loss: 1.9203 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4212 - val_loss: 1.9213 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0089 - accuracy: 0.4217 - val_loss: 1.9145 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4172 - val_loss: 1.9184 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4268 - val_loss: 1.9163 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4071 - val_loss: 1.9191 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.9157 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4217 - val_loss: 1.9166 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4178 - val_loss: 1.9177 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.9181 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4043 - val_loss: 1.9184 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4262 - val_loss: 1.9206 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.9207 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4240 - val_loss: 1.9192 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0089 - accuracy: 0.4116 - val_loss: 1.9183 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4274 - val_loss: 1.9153 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4262 - val_loss: 1.9167 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0089 - accuracy: 0.4262 - val_loss: 1.9181 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4291 - val_loss: 1.9113 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4279 - val_loss: 1.9213 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4291 - val_loss: 1.9194 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4285 - val_loss: 1.9184 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4240 - val_loss: 1.9189 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4217 - val_loss: 1.9188 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4240 - val_loss: 1.9230 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4262 - val_loss: 1.9184 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4172 - val_loss: 1.9197 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4195 - val_loss: 1.9226 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4268 - val_loss: 1.9162 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4212 - val_loss: 1.9171 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4240 - val_loss: 1.9163 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0089 - accuracy: 0.4251 - val_loss: 1.9190 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0089 - accuracy: 0.4184 - val_loss: 1.9225 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4262 - val_loss: 1.9191 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4144 - val_loss: 1.9197 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.9222 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4161 - val_loss: 1.9197 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4200 - val_loss: 1.9183 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4195 - val_loss: 1.9132 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4234 - val_loss: 1.9144 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4274 - val_loss: 1.9168 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4212 - val_loss: 1.9165 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4206 - val_loss: 1.9160 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4234 - val_loss: 1.9204 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4268 - val_loss: 1.9196 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4206 - val_loss: 1.9174 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4268 - val_loss: 1.9160 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4150 - val_loss: 1.9160 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.9147 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.9171 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4184 - val_loss: 1.9147 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.9179 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4110 - val_loss: 1.9222 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4133 - val_loss: 1.9181 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 1.0089 - accuracy: 0.4251 - val_loss: 1.9157 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0089 - accuracy: 0.4234 - val_loss: 1.9216 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0089 - accuracy: 0.4352 - val_loss: 1.9224 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4285 - val_loss: 1.9213 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4262 - val_loss: 1.9165 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4234 - val_loss: 1.9193 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/200\n",
      "222/222 [==============================] - 1s 5ms/step - loss: 1.0090 - accuracy: 0.4178 - val_loss: 1.9175 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4150 - val_loss: 1.9215 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4127 - val_loss: 1.9211 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4229 - val_loss: 1.9191 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4268 - val_loss: 1.9190 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4251 - val_loss: 1.9158 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4274 - val_loss: 1.9173 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0089 - accuracy: 0.4251 - val_loss: 1.9181 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4099 - val_loss: 1.9127 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4217 - val_loss: 1.9171 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9176 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4336 - val_loss: 1.9169 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4161 - val_loss: 1.9177 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4206 - val_loss: 1.9148 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4161 - val_loss: 1.9128 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4189 - val_loss: 1.9145 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0091 - accuracy: 0.4229 - val_loss: 1.9146 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.9182 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4155 - val_loss: 1.9181 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4184 - val_loss: 1.9183 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4251 - val_loss: 1.9225 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4161 - val_loss: 1.9221 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.9182 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4110 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0089 - accuracy: 0.4240 - val_loss: 1.9209 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4172 - val_loss: 1.9197 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4206 - val_loss: 1.9167 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0089 - accuracy: 0.4279 - val_loss: 1.9184 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4150 - val_loss: 1.9229 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4088 - val_loss: 1.9216 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0089 - accuracy: 0.4212 - val_loss: 1.9208 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4127 - val_loss: 1.9199 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4274 - val_loss: 1.9191 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0089 - accuracy: 0.4274 - val_loss: 1.9174 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4200 - val_loss: 1.9202 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4195 - val_loss: 1.9206 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4189 - val_loss: 1.9148 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4093 - val_loss: 1.9136 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4139 - val_loss: 1.9134 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4223 - val_loss: 1.9148 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4133 - val_loss: 1.9149 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4240 - val_loss: 1.9215 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4291 - val_loss: 1.9212 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4279 - val_loss: 1.9196 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0089 - accuracy: 0.4195 - val_loss: 1.9172 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9130 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4105 - val_loss: 1.9099 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4003 - val_loss: 1.9094 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4150 - val_loss: 1.9133 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4110 - val_loss: 1.9172 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4195 - val_loss: 1.9181 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4257 - val_loss: 1.9191 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.9224 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4178 - val_loss: 1.9175 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4279 - val_loss: 1.9142 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4184 - val_loss: 1.9182 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4251 - val_loss: 1.9209 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4251 - val_loss: 1.9198 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0089 - accuracy: 0.4285 - val_loss: 1.9200 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4150 - val_loss: 1.9169 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4279 - val_loss: 1.9189 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/200\n",
      "222/222 [==============================] - 1s 4ms/step - loss: 1.0090 - accuracy: 0.4217 - val_loss: 1.9192 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0089 - accuracy: 0.4212 - val_loss: 1.9216 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4240 - val_loss: 1.9212 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4178 - val_loss: 1.9212 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.9233 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4082 - val_loss: 1.9231 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4116 - val_loss: 1.9224 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.9216 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4167 - val_loss: 1.9232 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0089 - accuracy: 0.4302 - val_loss: 1.9204 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4217 - val_loss: 1.9190 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4189 - val_loss: 1.9199 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/200\n",
      "222/222 [==============================] - 1s 3ms/step - loss: 1.0090 - accuracy: 0.4274 - val_loss: 1.9237 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.2506 - accuracy: 0.3150\n",
      "Epoch 1/5\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 587899.5000 - accuracy: 0.4071 - val_loss: 1.2820 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0457 - accuracy: 0.4257 - val_loss: 1.4190 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0302 - accuracy: 0.4161 - val_loss: 1.5239 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0215 - accuracy: 0.4296 - val_loss: 1.6065 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0165 - accuracy: 0.4189 - val_loss: 1.6685 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.1876 - accuracy: 0.3150\n",
      "Epoch 1/10\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 142947.0156 - accuracy: 0.4206 - val_loss: 1.2868 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0450 - accuracy: 0.4296 - val_loss: 1.4228 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0297 - accuracy: 0.4172 - val_loss: 1.5284 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0212 - accuracy: 0.4296 - val_loss: 1.6090 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0164 - accuracy: 0.4296 - val_loss: 1.6718 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0135 - accuracy: 0.4296 - val_loss: 1.7215 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0117 - accuracy: 0.4212 - val_loss: 1.7604 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0107 - accuracy: 0.4279 - val_loss: 1.7907 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0100 - accuracy: 0.4296 - val_loss: 1.8159 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0096 - accuracy: 0.4279 - val_loss: 1.8355 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.2277 - accuracy: 0.3150\n",
      "Epoch 1/20\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 173583.9219 - accuracy: 0.4251 - val_loss: 1.2725 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0469 - accuracy: 0.4296 - val_loss: 1.4120 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0308 - accuracy: 0.4274 - val_loss: 1.5195 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0218 - accuracy: 0.4296 - val_loss: 1.6031 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0167 - accuracy: 0.4296 - val_loss: 1.6679 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0137 - accuracy: 0.4296 - val_loss: 1.7179 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0119 - accuracy: 0.4296 - val_loss: 1.7571 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0108 - accuracy: 0.4257 - val_loss: 1.7882 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0101 - accuracy: 0.4296 - val_loss: 1.8128 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0097 - accuracy: 0.4296 - val_loss: 1.8327 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0094 - accuracy: 0.4296 - val_loss: 1.8498 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0091 - accuracy: 0.4296 - val_loss: 1.8634 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0091 - accuracy: 0.4206 - val_loss: 1.8735 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0090 - accuracy: 0.4212 - val_loss: 1.8821 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8884 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0089 - accuracy: 0.4285 - val_loss: 1.8944 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8984 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4268 - val_loss: 1.9017 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0089 - accuracy: 0.4285 - val_loss: 1.9052 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9078 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.2464 - accuracy: 0.3150\n",
      "Epoch 1/50\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 775784.8125 - accuracy: 0.4200 - val_loss: 1.2772 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0464 - accuracy: 0.4240 - val_loss: 1.4139 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0306 - accuracy: 0.4245 - val_loss: 1.5215 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0217 - accuracy: 0.4200 - val_loss: 1.6036 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0166 - accuracy: 0.4296 - val_loss: 1.6677 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0136 - accuracy: 0.4296 - val_loss: 1.7183 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0119 - accuracy: 0.4296 - val_loss: 1.7573 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0108 - accuracy: 0.4240 - val_loss: 1.7890 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0100 - accuracy: 0.4296 - val_loss: 1.8139 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0096 - accuracy: 0.4296 - val_loss: 1.8334 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0093 - accuracy: 0.4274 - val_loss: 1.8501 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0091 - accuracy: 0.4206 - val_loss: 1.8630 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0091 - accuracy: 0.4296 - val_loss: 1.8746 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8828 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0089 - accuracy: 0.4279 - val_loss: 1.8891 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4229 - val_loss: 1.8959 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8998 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4184 - val_loss: 1.9035 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9063 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0089 - accuracy: 0.4206 - val_loss: 1.9085 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4212 - val_loss: 1.9106 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4150 - val_loss: 1.9116 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9124 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4268 - val_loss: 1.9143 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4229 - val_loss: 1.9152 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9148 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "111/111 [==============================] - 1s 7ms/step - loss: 1.0089 - accuracy: 0.4268 - val_loss: 1.9156 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9151 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4274 - val_loss: 1.9155 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9165 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9176 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9177 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4234 - val_loss: 1.9185 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4257 - val_loss: 1.9180 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4251 - val_loss: 1.9180 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4200 - val_loss: 1.9179 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9179 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4184 - val_loss: 1.9180 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9171 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9171 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4223 - val_loss: 1.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9171 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9174 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4268 - val_loss: 1.9177 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9183 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9177 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9189 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4245 - val_loss: 1.9196 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4229 - val_loss: 1.9198 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.2496 - accuracy: 0.3150\n",
      "Epoch 1/100\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 262451.3750 - accuracy: 0.3992 - val_loss: 1.2748 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0465 - accuracy: 0.4172 - val_loss: 1.4149 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0305 - accuracy: 0.4122 - val_loss: 1.5217 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0217 - accuracy: 0.4212 - val_loss: 1.6037 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0166 - accuracy: 0.4296 - val_loss: 1.6677 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0137 - accuracy: 0.4296 - val_loss: 1.7180 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0119 - accuracy: 0.4296 - val_loss: 1.7572 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0108 - accuracy: 0.4296 - val_loss: 1.7877 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0101 - accuracy: 0.4296 - val_loss: 1.8148 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0096 - accuracy: 0.4144 - val_loss: 1.8345 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0093 - accuracy: 0.4296 - val_loss: 1.8505 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0092 - accuracy: 0.4296 - val_loss: 1.8636 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0090 - accuracy: 0.4285 - val_loss: 1.8734 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.8824 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8897 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8953 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0089 - accuracy: 0.4279 - val_loss: 1.8985 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4234 - val_loss: 1.9022 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4251 - val_loss: 1.9039 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4167 - val_loss: 1.9063 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4167 - val_loss: 1.9091 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9105 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9116 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4110 - val_loss: 1.9125 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9144 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9148 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9151 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9155 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9158 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9157 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4229 - val_loss: 1.9163 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9150 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4268 - val_loss: 1.9150 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4279 - val_loss: 1.9169 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9173 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4285 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9169 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9166 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9173 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4274 - val_loss: 1.9184 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4217 - val_loss: 1.9175 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9177 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9180 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4279 - val_loss: 1.9186 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9192 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4133 - val_loss: 1.9192 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9186 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4291 - val_loss: 1.9181 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9185 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4206 - val_loss: 1.9188 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4212 - val_loss: 1.9193 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4274 - val_loss: 1.9190 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4184 - val_loss: 1.9194 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9187 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9201 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9192 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9191 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9191 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9182 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4223 - val_loss: 1.9174 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9183 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9179 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9181 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9184 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9183 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9182 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9179 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9181 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4313 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4229 - val_loss: 1.9180 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9174 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9171 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4217 - val_loss: 1.9169 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9164 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4234 - val_loss: 1.9174 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4217 - val_loss: 1.9180 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4178 - val_loss: 1.9182 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9181 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0089 - accuracy: 0.4229 - val_loss: 1.9176 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9190 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9186 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4279 - val_loss: 1.9185 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9195 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9190 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9190 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4251 - val_loss: 1.9189 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9185 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4274 - val_loss: 1.9174 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9180 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4257 - val_loss: 1.9179 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4285 - val_loss: 1.9174 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9177 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9188 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9187 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9180 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4257 - val_loss: 1.9194 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0089 - accuracy: 0.4262 - val_loss: 1.9199 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9201 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.2497 - accuracy: 0.3150\n",
      "Epoch 1/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 751675.4375 - accuracy: 0.4144 - val_loss: 1.2700 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0473 - accuracy: 0.4296 - val_loss: 1.4102 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0310 - accuracy: 0.4296 - val_loss: 1.5175 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0220 - accuracy: 0.4144 - val_loss: 1.6005 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0168 - accuracy: 0.4296 - val_loss: 1.6659 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0138 - accuracy: 0.4296 - val_loss: 1.7152 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0119 - accuracy: 0.4296 - val_loss: 1.7541 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0109 - accuracy: 0.4296 - val_loss: 1.7859 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0101 - accuracy: 0.4296 - val_loss: 1.8125 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0097 - accuracy: 0.4296 - val_loss: 1.8334 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0094 - accuracy: 0.4167 - val_loss: 1.8503 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 1.0091 - accuracy: 0.4296 - val_loss: 1.8635 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.8744 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.8828 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "111/111 [==============================] - 1s 7ms/step - loss: 1.0089 - accuracy: 0.4172 - val_loss: 1.8909 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0089 - accuracy: 0.4274 - val_loss: 1.8966 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0089 - accuracy: 0.4234 - val_loss: 1.8998 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 1.0088 - accuracy: 0.4088 - val_loss: 1.9026 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9073 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9090 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0089 - accuracy: 0.4262 - val_loss: 1.9106 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4229 - val_loss: 1.9115 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9142 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9140 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9144 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9153 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4251 - val_loss: 1.9165 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4274 - val_loss: 1.9164 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9163 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0089 - accuracy: 0.4172 - val_loss: 1.9163 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9171 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 1.0088 - accuracy: 0.4262 - val_loss: 1.9176 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9177 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9185 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9173 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9171 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4229 - val_loss: 1.9184 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9180 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0089 - accuracy: 0.4195 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9174 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0089 - accuracy: 0.4279 - val_loss: 1.9172 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4257 - val_loss: 1.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4184 - val_loss: 1.9188 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9183 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4223 - val_loss: 1.9187 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9195 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4285 - val_loss: 1.9200 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9193 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4240 - val_loss: 1.9195 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9193 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9183 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4223 - val_loss: 1.9185 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4234 - val_loss: 1.9185 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4268 - val_loss: 1.9172 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4245 - val_loss: 1.9169 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9157 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9155 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4257 - val_loss: 1.9146 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9154 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9151 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9166 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9163 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4245 - val_loss: 1.9166 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9179 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9160 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9168 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4229 - val_loss: 1.9176 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9177 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4167 - val_loss: 1.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/200\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4268 - val_loss: 1.9182 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9182 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4178 - val_loss: 1.9190 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9188 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9183 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9188 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9183 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/200\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9172 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/200\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9172 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9169 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/200\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4274 - val_loss: 1.9172 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9181 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/200\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4167 - val_loss: 1.9176 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9182 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4150 - val_loss: 1.9176 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/200\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9174 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9164 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/200\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0089 - accuracy: 0.4223 - val_loss: 1.9166 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/200\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9180 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/200\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4212 - val_loss: 1.9173 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9181 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/200\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4195 - val_loss: 1.9189 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/200\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9199 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/200\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9194 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9184 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9185 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/200\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9190 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4167 - val_loss: 1.9193 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.3964 - val_loss: 1.9195 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9192 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9173 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4268 - val_loss: 1.9175 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4274 - val_loss: 1.9175 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9177 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9187 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9189 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4285 - val_loss: 1.9191 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9201 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4206 - val_loss: 1.9196 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/200\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9187 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4212 - val_loss: 1.9182 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/200\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9181 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/200\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9173 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9177 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/200\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4167 - val_loss: 1.9185 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9180 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/200\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4240 - val_loss: 1.9165 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/200\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9166 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9162 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/200\n",
      "111/111 [==============================] - 0s 3ms/step - loss: 1.0088 - accuracy: 0.4257 - val_loss: 1.9168 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4172 - val_loss: 1.9167 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9166 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4234 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9167 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4285 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4257 - val_loss: 1.9165 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9159 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9141 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9146 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9150 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9159 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4245 - val_loss: 1.9172 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4285 - val_loss: 1.9172 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9174 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9174 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4206 - val_loss: 1.9176 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4257 - val_loss: 1.9184 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9188 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4200 - val_loss: 1.9179 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9185 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9181 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9184 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4279 - val_loss: 1.9182 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9179 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 1.0088 - accuracy: 0.4234 - val_loss: 1.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4217 - val_loss: 1.9191 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9183 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9193 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9183 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/200\n",
      "111/111 [==============================] - 1s 7ms/step - loss: 1.0088 - accuracy: 0.4144 - val_loss: 1.9183 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/200\n",
      "111/111 [==============================] - 1s 6ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9190 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9190 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0089 - accuracy: 0.4110 - val_loss: 1.9189 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9182 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4262 - val_loss: 1.9175 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9195 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4184 - val_loss: 1.9195 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4279 - val_loss: 1.9193 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9184 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4229 - val_loss: 1.9185 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4139 - val_loss: 1.9184 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9180 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9185 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9181 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9180 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9175 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4274 - val_loss: 1.9172 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9166 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4172 - val_loss: 1.9169 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9180 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9173 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9172 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4105 - val_loss: 1.9171 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9162 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4262 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9172 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0089 - accuracy: 0.4279 - val_loss: 1.9177 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9183 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9173 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4189 - val_loss: 1.9167 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9174 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4268 - val_loss: 1.9176 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.9177 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4268 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9158 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9157 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4285 - val_loss: 1.9158 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9167 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9172 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4257 - val_loss: 1.9175 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4206 - val_loss: 1.9177 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4139 - val_loss: 1.9176 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/200\n",
      "111/111 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9177 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/200\n",
      "111/111 [==============================] - 1s 5ms/step - loss: 1.0088 - accuracy: 0.4268 - val_loss: 1.9182 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.2492 - accuracy: 0.3150\n",
      "Epoch 1/5\n",
      "56/56 [==============================] - 1s 8ms/step - loss: 674697.5000 - accuracy: 0.4155 - val_loss: 1.1874 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0671 - accuracy: 0.4234 - val_loss: 1.2744 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0519 - accuracy: 0.4110 - val_loss: 1.3502 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0411 - accuracy: 0.4161 - val_loss: 1.4160 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0332 - accuracy: 0.4223 - val_loss: 1.4733 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.1471 - accuracy: 0.3150\n",
      "Epoch 1/10\n",
      "56/56 [==============================] - 1s 8ms/step - loss: 320173.8750 - accuracy: 0.4268 - val_loss: 1.1997 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0648 - accuracy: 0.4274 - val_loss: 1.2846 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0504 - accuracy: 0.4296 - val_loss: 1.3577 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0401 - accuracy: 0.4296 - val_loss: 1.4218 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0325 - accuracy: 0.4296 - val_loss: 1.4784 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0269 - accuracy: 0.4296 - val_loss: 1.5280 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0227 - accuracy: 0.4296 - val_loss: 1.5708 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0196 - accuracy: 0.4296 - val_loss: 1.6085 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0172 - accuracy: 0.4296 - val_loss: 1.6428 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0153 - accuracy: 0.4296 - val_loss: 1.6711 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.1881 - accuracy: 0.3150\n",
      "Epoch 1/20\n",
      "56/56 [==============================] - 1s 8ms/step - loss: 902547.8125 - accuracy: 0.3981 - val_loss: 1.1906 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0665 - accuracy: 0.4274 - val_loss: 1.2762 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0516 - accuracy: 0.4020 - val_loss: 1.3514 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0409 - accuracy: 0.4296 - val_loss: 1.4162 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0332 - accuracy: 0.4296 - val_loss: 1.4740 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0273 - accuracy: 0.4189 - val_loss: 1.5244 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0230 - accuracy: 0.4296 - val_loss: 1.5681 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0198 - accuracy: 0.4296 - val_loss: 1.6072 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0173 - accuracy: 0.4296 - val_loss: 1.6411 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0154 - accuracy: 0.4296 - val_loss: 1.6715 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0139 - accuracy: 0.4296 - val_loss: 1.6984 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0128 - accuracy: 0.4251 - val_loss: 1.7225 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0120 - accuracy: 0.4285 - val_loss: 1.7423 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0113 - accuracy: 0.4296 - val_loss: 1.7607 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0108 - accuracy: 0.4296 - val_loss: 1.7772 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0104 - accuracy: 0.4296 - val_loss: 1.7900 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0101 - accuracy: 0.4296 - val_loss: 1.8034 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0098 - accuracy: 0.4296 - val_loss: 1.8164 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0096 - accuracy: 0.4296 - val_loss: 1.8271 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0094 - accuracy: 0.4296 - val_loss: 1.8365 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.2280 - accuracy: 0.3150\n",
      "Epoch 1/50\n",
      "56/56 [==============================] - 1s 8ms/step - loss: 110149.4688 - accuracy: 0.4212 - val_loss: 1.1900 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0666 - accuracy: 0.4240 - val_loss: 1.2771 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0515 - accuracy: 0.4296 - val_loss: 1.3518 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0408 - accuracy: 0.4296 - val_loss: 1.4175 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0330 - accuracy: 0.4229 - val_loss: 1.4745 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0273 - accuracy: 0.4296 - val_loss: 1.5248 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0230 - accuracy: 0.4296 - val_loss: 1.5678 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 1.0198 - accuracy: 0.4296 - val_loss: 1.6059 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0174 - accuracy: 0.4296 - val_loss: 1.6396 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0155 - accuracy: 0.4296 - val_loss: 1.6698 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0141 - accuracy: 0.4296 - val_loss: 1.6968 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0129 - accuracy: 0.4296 - val_loss: 1.7200 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0120 - accuracy: 0.4296 - val_loss: 1.7405 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0114 - accuracy: 0.4296 - val_loss: 1.7584 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0108 - accuracy: 0.4296 - val_loss: 1.7744 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0105 - accuracy: 0.4296 - val_loss: 1.7894 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0101 - accuracy: 0.4296 - val_loss: 1.8028 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0098 - accuracy: 0.4296 - val_loss: 1.8148 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0096 - accuracy: 0.4296 - val_loss: 1.8258 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0094 - accuracy: 0.4296 - val_loss: 1.8357 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0093 - accuracy: 0.4296 - val_loss: 1.8448 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0092 - accuracy: 0.4296 - val_loss: 1.8522 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0091 - accuracy: 0.4296 - val_loss: 1.8601 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.8650 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.8712 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8764 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8807 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8846 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8877 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8903 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8935 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8964 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8983 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8999 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9016 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9031 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9054 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9069 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9073 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9088 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9101 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9115 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9110 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9124 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9129 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9144 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9157 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9156 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9160 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9150 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2483 - accuracy: 0.3150\n",
      "Epoch 1/100\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 677227.4375 - accuracy: 0.3992 - val_loss: 1.1914 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0663 - accuracy: 0.4296 - val_loss: 1.2777 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0514 - accuracy: 0.4167 - val_loss: 1.3525 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0407 - accuracy: 0.4296 - val_loss: 1.4181 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0329 - accuracy: 0.4296 - val_loss: 1.4740 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0273 - accuracy: 0.4296 - val_loss: 1.5238 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0231 - accuracy: 0.4296 - val_loss: 1.5676 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0198 - accuracy: 0.4296 - val_loss: 1.6066 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0173 - accuracy: 0.4296 - val_loss: 1.6405 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0155 - accuracy: 0.4296 - val_loss: 1.6698 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0140 - accuracy: 0.4296 - val_loss: 1.6977 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0129 - accuracy: 0.4296 - val_loss: 1.7210 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0120 - accuracy: 0.4296 - val_loss: 1.7420 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0113 - accuracy: 0.4296 - val_loss: 1.7606 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0108 - accuracy: 0.4296 - val_loss: 1.7776 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0103 - accuracy: 0.4296 - val_loss: 1.7918 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0100 - accuracy: 0.4296 - val_loss: 1.8049 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0098 - accuracy: 0.4296 - val_loss: 1.8164 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0096 - accuracy: 0.4296 - val_loss: 1.8277 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0094 - accuracy: 0.4296 - val_loss: 1.8373 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0093 - accuracy: 0.4296 - val_loss: 1.8459 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0092 - accuracy: 0.4296 - val_loss: 1.8537 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0091 - accuracy: 0.4296 - val_loss: 1.8604 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.8655 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.8716 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8764 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8804 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8849 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8880 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8907 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8937 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8940 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8968 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8991 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9008 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9008 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9029 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4245 - val_loss: 1.9051 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9060 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9065 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9079 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9090 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9094 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9082 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9088 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9080 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9087 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9105 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9110 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4240 - val_loss: 1.9114 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9107 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9121 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9115 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9116 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9133 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9140 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9137 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9150 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9137 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9137 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4178 - val_loss: 1.9143 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9151 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9166 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9148 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9138 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9143 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9152 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9152 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9158 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9161 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9160 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9163 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9165 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9168 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9176 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9171 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9172 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9181 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9177 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9183 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9169 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9172 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9168 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9164 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9173 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9172 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9172 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9169 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9166 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9158 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9150 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9147 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9141 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9139 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9155 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9161 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9165 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.2487 - accuracy: 0.3150\n",
      "Epoch 1/200\n",
      "56/56 [==============================] - 1s 8ms/step - loss: 1100482.6250 - accuracy: 0.3986 - val_loss: 1.1911 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0664 - accuracy: 0.4251 - val_loss: 1.2769 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0515 - accuracy: 0.4257 - val_loss: 1.3519 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0408 - accuracy: 0.4296 - val_loss: 1.4164 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0331 - accuracy: 0.4296 - val_loss: 1.4723 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0275 - accuracy: 0.4116 - val_loss: 1.5225 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0232 - accuracy: 0.4296 - val_loss: 1.5658 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0200 - accuracy: 0.4296 - val_loss: 1.6033 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0175 - accuracy: 0.4296 - val_loss: 1.6377 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0156 - accuracy: 0.4296 - val_loss: 1.6668 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0142 - accuracy: 0.4296 - val_loss: 1.6944 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0130 - accuracy: 0.4296 - val_loss: 1.7184 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0121 - accuracy: 0.4296 - val_loss: 1.7398 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0114 - accuracy: 0.4296 - val_loss: 1.7584 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0109 - accuracy: 0.4150 - val_loss: 1.7746 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0104 - accuracy: 0.4296 - val_loss: 1.7897 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0101 - accuracy: 0.4296 - val_loss: 1.8033 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0098 - accuracy: 0.4217 - val_loss: 1.8148 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0096 - accuracy: 0.4229 - val_loss: 1.8251 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0095 - accuracy: 0.4296 - val_loss: 1.8344 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/200\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 1.0093 - accuracy: 0.4296 - val_loss: 1.8422 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/200\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 1.0092 - accuracy: 0.4296 - val_loss: 1.8512 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0091 - accuracy: 0.4296 - val_loss: 1.8571 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.8624 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.8678 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8732 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/200\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8778 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8814 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8847 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8871 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8892 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8927 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8952 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8975 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4167 - val_loss: 1.9002 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9015 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/200\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9033 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9052 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9064 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9061 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9080 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4262 - val_loss: 1.9086 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9093 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4206 - val_loss: 1.9105 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/200\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9112 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/200\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9124 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9129 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9128 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9133 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/200\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9126 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9132 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/200\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9142 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9139 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9138 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/200\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9133 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/200\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9132 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9131 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9130 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/200\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9128 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/200\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9130 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9132 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/200\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9135 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/200\n",
      "56/56 [==============================] - 0s 4ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9135 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9151 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9160 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/200\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9150 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9144 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9147 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9140 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9142 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9149 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4262 - val_loss: 1.9150 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9151 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9163 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9173 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/200\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9181 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/200\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9191 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/200\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.0087 - accuracy: 0.4262 - val_loss: 1.9188 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/200\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9179 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/200\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9177 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/200\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9180 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/200\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/200\n",
      "56/56 [==============================] - 1s 10ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9174 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/200\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9168 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9175 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9176 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/200\n",
      "56/56 [==============================] - 0s 8ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/200\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9176 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/200\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9174 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9184 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9182 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/200\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9182 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9179 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9185 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9187 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9179 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9179 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9179 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9182 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9172 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9163 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9149 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9144 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9150 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9154 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9149 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9155 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9163 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9162 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/200\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9164 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9161 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9161 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9173 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9171 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9188 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9184 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9173 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9174 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9187 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9184 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9179 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9181 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9176 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9167 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9171 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9177 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4240 - val_loss: 1.9183 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9184 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9190 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9192 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9193 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9189 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9176 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9177 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9185 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9183 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/200\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 1.0088 - accuracy: 0.4240 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9159 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9155 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4229 - val_loss: 1.9161 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/200\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9163 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/200\n",
      "56/56 [==============================] - 1s 9ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9165 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/200\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9169 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/200\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/200\n",
      "56/56 [==============================] - 0s 9ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9177 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/200\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9182 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9187 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/200\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9183 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9191 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9195 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9183 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9186 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9176 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9161 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9167 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9175 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9164 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9162 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9161 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9161 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9153 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9145 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9156 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9149 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9150 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9144 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9145 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9153 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9151 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9144 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9146 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9149 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9146 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/200\n",
      "56/56 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9158 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9155 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9143 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4257 - val_loss: 1.9138 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9143 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9152 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9153 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9160 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/200\n",
      "56/56 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9162 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9168 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9174 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9180 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9177 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9174 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9175 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0087 - accuracy: 0.4245 - val_loss: 1.9172 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9176 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/200\n",
      "56/56 [==============================] - 0s 5ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.9165 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.2487 - accuracy: 0.3150\n",
      "Epoch 1/5\n",
      "28/28 [==============================] - 1s 13ms/step - loss: 2257142.0000 - accuracy: 0.4110 - val_loss: 1.1367 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0827 - accuracy: 0.4077 - val_loss: 1.1844 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.0721 - accuracy: 0.4296 - val_loss: 1.2290 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0632 - accuracy: 0.4189 - val_loss: 1.2708 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.0556 - accuracy: 0.4296 - val_loss: 1.3100 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1202 - accuracy: 0.3150\n",
      "Epoch 1/10\n",
      "28/28 [==============================] - 1s 15ms/step - loss: 2077158.0000 - accuracy: 0.3964 - val_loss: 1.1427 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0820 - accuracy: 0.4189 - val_loss: 1.1903 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0708 - accuracy: 0.4251 - val_loss: 1.2349 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.0620 - accuracy: 0.4296 - val_loss: 1.2768 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0546 - accuracy: 0.4296 - val_loss: 1.3152 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0484 - accuracy: 0.4296 - val_loss: 1.3515 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0431 - accuracy: 0.4296 - val_loss: 1.3850 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0386 - accuracy: 0.4296 - val_loss: 1.4166 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0347 - accuracy: 0.4296 - val_loss: 1.4463 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 1.0314 - accuracy: 0.4296 - val_loss: 1.4738 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 1.1472 - accuracy: 0.3150\n",
      "Epoch 1/20\n",
      "28/28 [==============================] - 1s 15ms/step - loss: 2065379.0000 - accuracy: 0.3846 - val_loss: 1.1432 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0812 - accuracy: 0.4296 - val_loss: 1.1908 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0708 - accuracy: 0.4296 - val_loss: 1.2355 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0619 - accuracy: 0.4296 - val_loss: 1.2768 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0546 - accuracy: 0.4296 - val_loss: 1.3152 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0484 - accuracy: 0.4296 - val_loss: 1.3512 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0431 - accuracy: 0.4296 - val_loss: 1.3850 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0386 - accuracy: 0.4296 - val_loss: 1.4166 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0347 - accuracy: 0.4296 - val_loss: 1.4463 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0314 - accuracy: 0.4296 - val_loss: 1.4735 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0286 - accuracy: 0.4296 - val_loss: 1.4993 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0261 - accuracy: 0.4296 - val_loss: 1.5236 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0239 - accuracy: 0.4296 - val_loss: 1.5459 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0221 - accuracy: 0.4296 - val_loss: 1.5671 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0205 - accuracy: 0.4296 - val_loss: 1.5868 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0191 - accuracy: 0.4296 - val_loss: 1.6056 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0179 - accuracy: 0.4296 - val_loss: 1.6234 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0168 - accuracy: 0.4296 - val_loss: 1.6402 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0158 - accuracy: 0.4296 - val_loss: 1.6554 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0150 - accuracy: 0.4296 - val_loss: 1.6698 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.1879 - accuracy: 0.3150\n",
      "Epoch 1/50\n",
      "28/28 [==============================] - 1s 14ms/step - loss: 1482480.2500 - accuracy: 0.3896 - val_loss: 1.1489 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0799 - accuracy: 0.4296 - val_loss: 1.1958 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0697 - accuracy: 0.4217 - val_loss: 1.2399 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0611 - accuracy: 0.4296 - val_loss: 1.2810 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0539 - accuracy: 0.4296 - val_loss: 1.3194 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0478 - accuracy: 0.4296 - val_loss: 1.3551 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0426 - accuracy: 0.4296 - val_loss: 1.3888 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0381 - accuracy: 0.4296 - val_loss: 1.4201 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0343 - accuracy: 0.4296 - val_loss: 1.4492 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0310 - accuracy: 0.4296 - val_loss: 1.4766 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0282 - accuracy: 0.4296 - val_loss: 1.5023 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0258 - accuracy: 0.4296 - val_loss: 1.5261 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0237 - accuracy: 0.4296 - val_loss: 1.5486 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0219 - accuracy: 0.4296 - val_loss: 1.5697 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0203 - accuracy: 0.4296 - val_loss: 1.5894 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0189 - accuracy: 0.4296 - val_loss: 1.6077 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0177 - accuracy: 0.4296 - val_loss: 1.6251 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0167 - accuracy: 0.4296 - val_loss: 1.6416 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0158 - accuracy: 0.4296 - val_loss: 1.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0150 - accuracy: 0.4296 - val_loss: 1.6712 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0142 - accuracy: 0.4296 - val_loss: 1.6847 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0136 - accuracy: 0.4296 - val_loss: 1.6976 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0131 - accuracy: 0.4296 - val_loss: 1.7090 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0126 - accuracy: 0.4296 - val_loss: 1.7203 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0122 - accuracy: 0.4296 - val_loss: 1.7307 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0118 - accuracy: 0.4296 - val_loss: 1.7409 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0115 - accuracy: 0.4296 - val_loss: 1.7507 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0111 - accuracy: 0.4296 - val_loss: 1.7600 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0109 - accuracy: 0.4296 - val_loss: 1.7684 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0106 - accuracy: 0.4296 - val_loss: 1.7763 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0104 - accuracy: 0.4296 - val_loss: 1.7838 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0103 - accuracy: 0.4296 - val_loss: 1.7910 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0101 - accuracy: 0.4296 - val_loss: 1.7977 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0099 - accuracy: 0.4296 - val_loss: 1.8042 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0098 - accuracy: 0.4296 - val_loss: 1.8101 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0097 - accuracy: 0.4296 - val_loss: 1.8160 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0096 - accuracy: 0.4296 - val_loss: 1.8214 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0095 - accuracy: 0.4296 - val_loss: 1.8264 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0094 - accuracy: 0.4296 - val_loss: 1.8315 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0093 - accuracy: 0.4296 - val_loss: 1.8360 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0093 - accuracy: 0.4296 - val_loss: 1.8406 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0092 - accuracy: 0.4296 - val_loss: 1.8447 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0092 - accuracy: 0.4296 - val_loss: 1.8486 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0091 - accuracy: 0.4296 - val_loss: 1.8523 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0091 - accuracy: 0.4296 - val_loss: 1.8559 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.8590 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.8621 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.8651 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8679 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8705 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2367 - accuracy: 0.3150\n",
      "Epoch 1/100\n",
      "28/28 [==============================] - 1s 13ms/step - loss: 899196.0625 - accuracy: 0.4105 - val_loss: 1.1488 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0799 - accuracy: 0.4212 - val_loss: 1.1958 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.0697 - accuracy: 0.4296 - val_loss: 1.2400 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0611 - accuracy: 0.4296 - val_loss: 1.2812 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0539 - accuracy: 0.4296 - val_loss: 1.3197 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0477 - accuracy: 0.4296 - val_loss: 1.3555 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0425 - accuracy: 0.4296 - val_loss: 1.3891 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0381 - accuracy: 0.4296 - val_loss: 1.4203 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0343 - accuracy: 0.4296 - val_loss: 1.4494 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0310 - accuracy: 0.4296 - val_loss: 1.4767 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0282 - accuracy: 0.4217 - val_loss: 1.5024 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0258 - accuracy: 0.4296 - val_loss: 1.5265 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0237 - accuracy: 0.4296 - val_loss: 1.5488 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0219 - accuracy: 0.4296 - val_loss: 1.5696 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0203 - accuracy: 0.4296 - val_loss: 1.5891 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0189 - accuracy: 0.4296 - val_loss: 1.6080 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0177 - accuracy: 0.4296 - val_loss: 1.6254 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0167 - accuracy: 0.4296 - val_loss: 1.6419 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0157 - accuracy: 0.4296 - val_loss: 1.6571 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0150 - accuracy: 0.4296 - val_loss: 1.6714 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0143 - accuracy: 0.4296 - val_loss: 1.6852 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0136 - accuracy: 0.4296 - val_loss: 1.6979 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0131 - accuracy: 0.4296 - val_loss: 1.7101 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0126 - accuracy: 0.4296 - val_loss: 1.7215 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0121 - accuracy: 0.4296 - val_loss: 1.7319 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 1.0118 - accuracy: 0.4296 - val_loss: 1.7420 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0114 - accuracy: 0.4296 - val_loss: 1.7517 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0111 - accuracy: 0.4296 - val_loss: 1.7606 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0109 - accuracy: 0.4296 - val_loss: 1.7689 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0106 - accuracy: 0.4296 - val_loss: 1.7769 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0104 - accuracy: 0.4296 - val_loss: 1.7845 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0102 - accuracy: 0.4296 - val_loss: 1.7918 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0101 - accuracy: 0.4296 - val_loss: 1.7983 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0099 - accuracy: 0.4296 - val_loss: 1.8046 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0098 - accuracy: 0.4296 - val_loss: 1.8106 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0097 - accuracy: 0.4296 - val_loss: 1.8164 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0096 - accuracy: 0.4296 - val_loss: 1.8218 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0095 - accuracy: 0.4296 - val_loss: 1.8270 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0094 - accuracy: 0.4296 - val_loss: 1.8316 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0093 - accuracy: 0.4296 - val_loss: 1.8358 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0093 - accuracy: 0.4296 - val_loss: 1.8401 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0092 - accuracy: 0.4296 - val_loss: 1.8438 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0092 - accuracy: 0.4296 - val_loss: 1.8475 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0091 - accuracy: 0.4296 - val_loss: 1.8513 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0091 - accuracy: 0.4296 - val_loss: 1.8548 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.8581 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.8611 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.8639 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.8670 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8693 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8719 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8744 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8764 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8785 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8805 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8825 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8843 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8857 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8876 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8893 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8908 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8924 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8937 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8951 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8960 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.8971 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.8979 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.8989 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.8997 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9007 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9015 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9026 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9034 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9040 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9046 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9052 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9057 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9063 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9071 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9081 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9084 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9090 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9096 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9101 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9105 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9108 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9112 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9114 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9117 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9119 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9122 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9128 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9130 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9135 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9134 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9136 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9140 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9142 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9145 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9144 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.2481 - accuracy: 0.3150\n",
      "Epoch 1/200\n",
      "28/28 [==============================] - 1s 13ms/step - loss: 5.9019 - accuracy: 0.4178 - val_loss: 1.1462 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0805 - accuracy: 0.4234 - val_loss: 1.1935 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0702 - accuracy: 0.4234 - val_loss: 1.2378 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0615 - accuracy: 0.4229 - val_loss: 1.2795 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0541 - accuracy: 0.4296 - val_loss: 1.3182 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0479 - accuracy: 0.4268 - val_loss: 1.3540 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0427 - accuracy: 0.4296 - val_loss: 1.3877 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0382 - accuracy: 0.4296 - val_loss: 1.4192 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0344 - accuracy: 0.4296 - val_loss: 1.4482 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0312 - accuracy: 0.4296 - val_loss: 1.4754 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0284 - accuracy: 0.4296 - val_loss: 1.5011 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0259 - accuracy: 0.4296 - val_loss: 1.5252 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0238 - accuracy: 0.4296 - val_loss: 1.5477 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0220 - accuracy: 0.4296 - val_loss: 1.5689 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0204 - accuracy: 0.4296 - val_loss: 1.5889 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0190 - accuracy: 0.4296 - val_loss: 1.6075 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0178 - accuracy: 0.4296 - val_loss: 1.6253 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0167 - accuracy: 0.4296 - val_loss: 1.6416 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0157 - accuracy: 0.4296 - val_loss: 1.6569 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0150 - accuracy: 0.4296 - val_loss: 1.6714 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0143 - accuracy: 0.4296 - val_loss: 1.6849 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0136 - accuracy: 0.4296 - val_loss: 1.6973 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0131 - accuracy: 0.4296 - val_loss: 1.7095 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0126 - accuracy: 0.4296 - val_loss: 1.7209 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0122 - accuracy: 0.4296 - val_loss: 1.7314 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0118 - accuracy: 0.4296 - val_loss: 1.7414 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0115 - accuracy: 0.4296 - val_loss: 1.7511 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0111 - accuracy: 0.4296 - val_loss: 1.7602 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0109 - accuracy: 0.4296 - val_loss: 1.7686 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0106 - accuracy: 0.4296 - val_loss: 1.7769 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0104 - accuracy: 0.4296 - val_loss: 1.7844 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0102 - accuracy: 0.4296 - val_loss: 1.7918 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0101 - accuracy: 0.4296 - val_loss: 1.7984 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0099 - accuracy: 0.4296 - val_loss: 1.8049 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0098 - accuracy: 0.4296 - val_loss: 1.8109 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0097 - accuracy: 0.4296 - val_loss: 1.8165 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0096 - accuracy: 0.4296 - val_loss: 1.8219 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0095 - accuracy: 0.4296 - val_loss: 1.8271 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0094 - accuracy: 0.4296 - val_loss: 1.8314 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0093 - accuracy: 0.4296 - val_loss: 1.8361 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0093 - accuracy: 0.4296 - val_loss: 1.8403 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0092 - accuracy: 0.4296 - val_loss: 1.8444 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0091 - accuracy: 0.4296 - val_loss: 1.8481 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0091 - accuracy: 0.4296 - val_loss: 1.8518 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0091 - accuracy: 0.4296 - val_loss: 1.8552 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.8586 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.8618 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.8647 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8678 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8705 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8728 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8752 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8776 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8798 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8816 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8837 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8855 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8872 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8890 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8907 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8921 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.8935 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8949 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.8961 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.8971 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.8979 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.8992 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.8999 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9007 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9015 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9025 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9035 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9042 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9047 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/200\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9057 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9062 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9070 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9076 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9082 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9085 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9089 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9093 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9095 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9102 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9105 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9106 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9112 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9110 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9116 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9118 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9122 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9121 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9124 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9128 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9132 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9134 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9139 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9140 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9142 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9144 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9147 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9149 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9153 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9156 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9156 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/200\n",
      "28/28 [==============================] - 0s 6ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9158 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9162 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9162 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9166 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9165 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9166 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9167 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9165 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9168 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9173 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9173 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9172 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9171 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9169 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/200\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9167 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9166 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/200\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9164 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9165 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/200\n",
      "28/28 [==============================] - 0s 11ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9164 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/200\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9168 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9168 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9169 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9169 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9171 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9173 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9172 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9172 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9173 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9173 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9177 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9180 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9183 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9184 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9183 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9184 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9184 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9183 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9185 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9185 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9185 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9185 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9185 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9185 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9186 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9185 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9184 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9184 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9184 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9186 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9187 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9189 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9189 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9190 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9185 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9188 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/200\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9186 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9186 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9186 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9187 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9190 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9190 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9187 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9188 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9184 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9183 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9181 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9181 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9178 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9175 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9176 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9174 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9173 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9173 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/200\n",
      "28/28 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9171 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9169 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/200\n",
      "28/28 [==============================] - 0s 12ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9169 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9170 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9171 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9167 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9171 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/200\n",
      "28/28 [==============================] - 0s 8ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9171 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/200\n",
      "28/28 [==============================] - 0s 9ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9175 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9174 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/200\n",
      "28/28 [==============================] - 0s 7ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9176 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2490 - accuracy: 0.3150\n",
      "Epoch 1/5\n",
      "14/14 [==============================] - 1s 25ms/step - loss: 1213927.5000 - accuracy: 0.3660 - val_loss: 1.1178 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0903 - accuracy: 0.4195 - val_loss: 1.1429 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0841 - accuracy: 0.4296 - val_loss: 1.1672 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0784 - accuracy: 0.4296 - val_loss: 1.1905 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0731 - accuracy: 0.4296 - val_loss: 1.2131 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.1082 - accuracy: 0.3150\n",
      "Epoch 1/10\n",
      "14/14 [==============================] - 1s 25ms/step - loss: 1624033.0000 - accuracy: 0.4088 - val_loss: 1.1195 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0899 - accuracy: 0.4234 - val_loss: 1.1446 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/10\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 1.0837 - accuracy: 0.4234 - val_loss: 1.1687 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/10\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0780 - accuracy: 0.4184 - val_loss: 1.1920 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/10\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0728 - accuracy: 0.4184 - val_loss: 1.2146 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/10\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0681 - accuracy: 0.4296 - val_loss: 1.2365 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/10\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1.0637 - accuracy: 0.4217 - val_loss: 1.2576 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/10\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0597 - accuracy: 0.4296 - val_loss: 1.2780 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/10\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0560 - accuracy: 0.4296 - val_loss: 1.2976 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/10\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1.0527 - accuracy: 0.4296 - val_loss: 1.3166 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.1212 - accuracy: 0.3150\n",
      "Epoch 1/20\n",
      "14/14 [==============================] - 1s 23ms/step - loss: 464390.3438 - accuracy: 0.4127 - val_loss: 1.1277 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0878 - accuracy: 0.4296 - val_loss: 1.1525 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/20\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1.0818 - accuracy: 0.4296 - val_loss: 1.1763 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/20\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0763 - accuracy: 0.4296 - val_loss: 1.1994 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/20\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0712 - accuracy: 0.4296 - val_loss: 1.2218 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/20\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0666 - accuracy: 0.4296 - val_loss: 1.2433 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/20\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0624 - accuracy: 0.4296 - val_loss: 1.2640 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/20\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0585 - accuracy: 0.4296 - val_loss: 1.2841 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/20\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0550 - accuracy: 0.4296 - val_loss: 1.3036 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/20\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0517 - accuracy: 0.4296 - val_loss: 1.3224 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/20\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1.0487 - accuracy: 0.4296 - val_loss: 1.3405 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/20\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0459 - accuracy: 0.4296 - val_loss: 1.3580 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/20\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0433 - accuracy: 0.4296 - val_loss: 1.3749 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/20\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0409 - accuracy: 0.4296 - val_loss: 1.3913 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/20\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0388 - accuracy: 0.4296 - val_loss: 1.4071 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/20\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1.0367 - accuracy: 0.4296 - val_loss: 1.4225 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/20\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0348 - accuracy: 0.4296 - val_loss: 1.4373 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/20\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0331 - accuracy: 0.4296 - val_loss: 1.4515 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/20\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0315 - accuracy: 0.4296 - val_loss: 1.4653 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/20\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0300 - accuracy: 0.4296 - val_loss: 1.4787 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.1481 - accuracy: 0.3150\n",
      "Epoch 1/50\n",
      "14/14 [==============================] - 1s 24ms/step - loss: 4184150.7500 - accuracy: 0.3806 - val_loss: 1.1179 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0903 - accuracy: 0.4155 - val_loss: 1.1430 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0840 - accuracy: 0.4296 - val_loss: 1.1672 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0783 - accuracy: 0.4296 - val_loss: 1.1906 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0731 - accuracy: 0.4296 - val_loss: 1.2133 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0684 - accuracy: 0.4296 - val_loss: 1.2352 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0640 - accuracy: 0.4296 - val_loss: 1.2562 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0600 - accuracy: 0.4296 - val_loss: 1.2766 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0563 - accuracy: 0.4296 - val_loss: 1.2962 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0529 - accuracy: 0.4296 - val_loss: 1.3153 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0498 - accuracy: 0.4296 - val_loss: 1.3336 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0469 - accuracy: 0.4296 - val_loss: 1.3513 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0443 - accuracy: 0.4296 - val_loss: 1.3685 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0418 - accuracy: 0.4296 - val_loss: 1.3851 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0396 - accuracy: 0.4296 - val_loss: 1.4011 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0375 - accuracy: 0.4296 - val_loss: 1.4167 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0356 - accuracy: 0.4296 - val_loss: 1.4316 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 1.0338 - accuracy: 0.4296 - val_loss: 1.4461 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1.0321 - accuracy: 0.4296 - val_loss: 1.4602 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1.0306 - accuracy: 0.4296 - val_loss: 1.4737 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0292 - accuracy: 0.4296 - val_loss: 1.4869 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1.0278 - accuracy: 0.4296 - val_loss: 1.4995 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1.0266 - accuracy: 0.4296 - val_loss: 1.5117 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0255 - accuracy: 0.4296 - val_loss: 1.5238 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0244 - accuracy: 0.4296 - val_loss: 1.5352 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0234 - accuracy: 0.4296 - val_loss: 1.5463 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0225 - accuracy: 0.4296 - val_loss: 1.5572 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0216 - accuracy: 0.4296 - val_loss: 1.5675 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 1.0208 - accuracy: 0.4296 - val_loss: 1.5776 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 1.0201 - accuracy: 0.4296 - val_loss: 1.5873 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1.0194 - accuracy: 0.4296 - val_loss: 1.5968 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0187 - accuracy: 0.4296 - val_loss: 1.6059 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0181 - accuracy: 0.4296 - val_loss: 1.6148 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0176 - accuracy: 0.4296 - val_loss: 1.6234 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0170 - accuracy: 0.4296 - val_loss: 1.6317 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0165 - accuracy: 0.4296 - val_loss: 1.6399 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1.0161 - accuracy: 0.4296 - val_loss: 1.6478 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0156 - accuracy: 0.4296 - val_loss: 1.6554 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 1.0152 - accuracy: 0.4296 - val_loss: 1.6628 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0148 - accuracy: 0.4296 - val_loss: 1.6699 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0144 - accuracy: 0.4296 - val_loss: 1.6768 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1.0141 - accuracy: 0.4296 - val_loss: 1.6835 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0138 - accuracy: 0.4296 - val_loss: 1.6901 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1.0135 - accuracy: 0.4296 - val_loss: 1.6965 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 1.0132 - accuracy: 0.4296 - val_loss: 1.7026 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0130 - accuracy: 0.4296 - val_loss: 1.7086 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 1.0127 - accuracy: 0.4296 - val_loss: 1.7144 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0125 - accuracy: 0.4296 - val_loss: 1.7199 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0123 - accuracy: 0.4296 - val_loss: 1.7254 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0121 - accuracy: 0.4296 - val_loss: 1.7307 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2020 - accuracy: 0.3150\n",
      "Epoch 1/100\n",
      "14/14 [==============================] - 1s 30ms/step - loss: 292543.3438 - accuracy: 0.3863 - val_loss: 1.1179 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 1.0903 - accuracy: 0.4195 - val_loss: 1.1429 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0841 - accuracy: 0.4296 - val_loss: 1.1672 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0784 - accuracy: 0.4296 - val_loss: 1.1905 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 1.0732 - accuracy: 0.4296 - val_loss: 1.2131 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0684 - accuracy: 0.4296 - val_loss: 1.2350 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1.0640 - accuracy: 0.4296 - val_loss: 1.2561 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0600 - accuracy: 0.4296 - val_loss: 1.2766 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0563 - accuracy: 0.4296 - val_loss: 1.2962 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 1.0529 - accuracy: 0.4296 - val_loss: 1.3153 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0498 - accuracy: 0.4296 - val_loss: 1.3337 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 1.0469 - accuracy: 0.4296 - val_loss: 1.3514 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0443 - accuracy: 0.4296 - val_loss: 1.3686 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0418 - accuracy: 0.4296 - val_loss: 1.3852 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1.0396 - accuracy: 0.4296 - val_loss: 1.4012 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0375 - accuracy: 0.4296 - val_loss: 1.4166 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0356 - accuracy: 0.4296 - val_loss: 1.4316 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 1.0338 - accuracy: 0.4296 - val_loss: 1.4461 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 1.0321 - accuracy: 0.4296 - val_loss: 1.4601 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0306 - accuracy: 0.4296 - val_loss: 1.4736 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 1.0292 - accuracy: 0.4296 - val_loss: 1.4868 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1.0278 - accuracy: 0.4296 - val_loss: 1.4995 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 1.0266 - accuracy: 0.4296 - val_loss: 1.5117 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 1.0255 - accuracy: 0.4296 - val_loss: 1.5236 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 1.0244 - accuracy: 0.4296 - val_loss: 1.5350 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0234 - accuracy: 0.4296 - val_loss: 1.5461 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0225 - accuracy: 0.4296 - val_loss: 1.5568 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0216 - accuracy: 0.4296 - val_loss: 1.5672 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0208 - accuracy: 0.4296 - val_loss: 1.5772 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0201 - accuracy: 0.4296 - val_loss: 1.5870 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1.0194 - accuracy: 0.4296 - val_loss: 1.5965 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0187 - accuracy: 0.4296 - val_loss: 1.6057 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0181 - accuracy: 0.4296 - val_loss: 1.6146 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0176 - accuracy: 0.4296 - val_loss: 1.6233 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0170 - accuracy: 0.4296 - val_loss: 1.6316 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0165 - accuracy: 0.4296 - val_loss: 1.6396 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0161 - accuracy: 0.4296 - val_loss: 1.6476 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1.0156 - accuracy: 0.4296 - val_loss: 1.6551 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0152 - accuracy: 0.4296 - val_loss: 1.6624 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1.0148 - accuracy: 0.4296 - val_loss: 1.6696 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1.0145 - accuracy: 0.4296 - val_loss: 1.6766 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0141 - accuracy: 0.4296 - val_loss: 1.6833 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0138 - accuracy: 0.4296 - val_loss: 1.6898 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1.0135 - accuracy: 0.4296 - val_loss: 1.6962 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0132 - accuracy: 0.4296 - val_loss: 1.7024 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0130 - accuracy: 0.4296 - val_loss: 1.7084 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0127 - accuracy: 0.4296 - val_loss: 1.7142 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0125 - accuracy: 0.4296 - val_loss: 1.7197 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1.0123 - accuracy: 0.4296 - val_loss: 1.7252 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0121 - accuracy: 0.4296 - val_loss: 1.7305 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0119 - accuracy: 0.4296 - val_loss: 1.7355 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0117 - accuracy: 0.4296 - val_loss: 1.7405 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1.0115 - accuracy: 0.4296 - val_loss: 1.7454 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0114 - accuracy: 0.4296 - val_loss: 1.7501 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0112 - accuracy: 0.4296 - val_loss: 1.7548 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1.0111 - accuracy: 0.4296 - val_loss: 1.7593 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0110 - accuracy: 0.4296 - val_loss: 1.7636 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0108 - accuracy: 0.4296 - val_loss: 1.7678 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0107 - accuracy: 0.4296 - val_loss: 1.7719 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0106 - accuracy: 0.4296 - val_loss: 1.7758 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0105 - accuracy: 0.4296 - val_loss: 1.7797 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0104 - accuracy: 0.4296 - val_loss: 1.7834 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0103 - accuracy: 0.4296 - val_loss: 1.7871 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0102 - accuracy: 0.4296 - val_loss: 1.7905 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0101 - accuracy: 0.4296 - val_loss: 1.7940 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0100 - accuracy: 0.4296 - val_loss: 1.7972 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 1.0100 - accuracy: 0.4296 - val_loss: 1.8005 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1.0099 - accuracy: 0.4296 - val_loss: 1.8037 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0098 - accuracy: 0.4296 - val_loss: 1.8067 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0098 - accuracy: 0.4296 - val_loss: 1.8096 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1.0097 - accuracy: 0.4296 - val_loss: 1.8126 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0096 - accuracy: 0.4296 - val_loss: 1.8154 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0096 - accuracy: 0.4296 - val_loss: 1.8182 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 1.0095 - accuracy: 0.4296 - val_loss: 1.8208 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0095 - accuracy: 0.4296 - val_loss: 1.8234 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 1.0095 - accuracy: 0.4296 - val_loss: 1.8258 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 1.0094 - accuracy: 0.4296 - val_loss: 1.8282 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "14/14 [==============================] - 0s 18ms/step - loss: 1.0094 - accuracy: 0.4296 - val_loss: 1.8306 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "14/14 [==============================] - 0s 22ms/step - loss: 1.0093 - accuracy: 0.4296 - val_loss: 1.8329 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "14/14 [==============================] - 0s 20ms/step - loss: 1.0093 - accuracy: 0.4296 - val_loss: 1.8351 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 1.0093 - accuracy: 0.4296 - val_loss: 1.8374 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 1.0093 - accuracy: 0.4296 - val_loss: 1.8394 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 1.0092 - accuracy: 0.4296 - val_loss: 1.8414 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 1.0092 - accuracy: 0.4296 - val_loss: 1.8434 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 1.0092 - accuracy: 0.4296 - val_loss: 1.8454 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "14/14 [==============================] - 0s 21ms/step - loss: 1.0091 - accuracy: 0.4296 - val_loss: 1.8474 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 1.0091 - accuracy: 0.4296 - val_loss: 1.8493 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 1.0091 - accuracy: 0.4296 - val_loss: 1.8512 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "14/14 [==============================] - 0s 19ms/step - loss: 1.0091 - accuracy: 0.4296 - val_loss: 1.8529 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.8546 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.8563 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.8579 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.8593 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.8608 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.8624 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8639 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8652 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8666 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8680 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8692 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 1.2364 - accuracy: 0.3150\n",
      "Epoch 1/200\n",
      "14/14 [==============================] - 1s 23ms/step - loss: 2254464.7500 - accuracy: 0.4032 - val_loss: 1.1276 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0879 - accuracy: 0.4234 - val_loss: 1.1524 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/200\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1.0818 - accuracy: 0.4234 - val_loss: 1.1763 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/200\n",
      "14/14 [==============================] - 0s 9ms/step - loss: 1.0763 - accuracy: 0.4234 - val_loss: 1.1995 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0713 - accuracy: 0.4234 - val_loss: 1.2218 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0667 - accuracy: 0.4234 - val_loss: 1.2434 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0624 - accuracy: 0.4234 - val_loss: 1.2641 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/200\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 1.0585 - accuracy: 0.4122 - val_loss: 1.2843 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0550 - accuracy: 0.4133 - val_loss: 1.3037 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/200\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0517 - accuracy: 0.4178 - val_loss: 1.3223 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0487 - accuracy: 0.4110 - val_loss: 1.3405 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0459 - accuracy: 0.4296 - val_loss: 1.3580 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0433 - accuracy: 0.4296 - val_loss: 1.3748 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0410 - accuracy: 0.4296 - val_loss: 1.3913 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0388 - accuracy: 0.4296 - val_loss: 1.4071 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0367 - accuracy: 0.4296 - val_loss: 1.4224 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0349 - accuracy: 0.4296 - val_loss: 1.4372 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0331 - accuracy: 0.4296 - val_loss: 1.4515 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0315 - accuracy: 0.4296 - val_loss: 1.4654 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0300 - accuracy: 0.4296 - val_loss: 1.4787 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0287 - accuracy: 0.4296 - val_loss: 1.4916 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0274 - accuracy: 0.4296 - val_loss: 1.5041 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0262 - accuracy: 0.4296 - val_loss: 1.5162 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0251 - accuracy: 0.4296 - val_loss: 1.5279 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0240 - accuracy: 0.4296 - val_loss: 1.5393 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0231 - accuracy: 0.4296 - val_loss: 1.5502 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/200\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0222 - accuracy: 0.4296 - val_loss: 1.5608 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0213 - accuracy: 0.4296 - val_loss: 1.5711 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0206 - accuracy: 0.4296 - val_loss: 1.5811 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0198 - accuracy: 0.4296 - val_loss: 1.5908 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0191 - accuracy: 0.4296 - val_loss: 1.6002 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/200\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 1.0185 - accuracy: 0.4296 - val_loss: 1.6092 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0179 - accuracy: 0.4296 - val_loss: 1.6181 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0173 - accuracy: 0.4296 - val_loss: 1.6265 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/200\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0168 - accuracy: 0.4296 - val_loss: 1.6347 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0163 - accuracy: 0.4296 - val_loss: 1.6427 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/200\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0159 - accuracy: 0.4296 - val_loss: 1.6504 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0155 - accuracy: 0.4296 - val_loss: 1.6579 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0151 - accuracy: 0.4296 - val_loss: 1.6652 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0147 - accuracy: 0.4296 - val_loss: 1.6723 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0143 - accuracy: 0.4296 - val_loss: 1.6792 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0140 - accuracy: 0.4296 - val_loss: 1.6859 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0137 - accuracy: 0.4296 - val_loss: 1.6924 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0134 - accuracy: 0.4296 - val_loss: 1.6987 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0131 - accuracy: 0.4296 - val_loss: 1.7048 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0129 - accuracy: 0.4296 - val_loss: 1.7106 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0126 - accuracy: 0.4296 - val_loss: 1.7164 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0124 - accuracy: 0.4296 - val_loss: 1.7219 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0122 - accuracy: 0.4296 - val_loss: 1.7274 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0120 - accuracy: 0.4296 - val_loss: 1.7326 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0118 - accuracy: 0.4296 - val_loss: 1.7376 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0116 - accuracy: 0.4296 - val_loss: 1.7426 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0115 - accuracy: 0.4296 - val_loss: 1.7475 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0113 - accuracy: 0.4296 - val_loss: 1.7522 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/200\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 1.0112 - accuracy: 0.4296 - val_loss: 1.7568 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0110 - accuracy: 0.4296 - val_loss: 1.7612 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/200\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 1.0109 - accuracy: 0.4296 - val_loss: 1.7655 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/200\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1.0108 - accuracy: 0.4296 - val_loss: 1.7696 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0107 - accuracy: 0.4296 - val_loss: 1.7735 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0105 - accuracy: 0.4296 - val_loss: 1.7774 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0104 - accuracy: 0.4296 - val_loss: 1.7814 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0103 - accuracy: 0.4296 - val_loss: 1.7852 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0102 - accuracy: 0.4296 - val_loss: 1.7888 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0101 - accuracy: 0.4296 - val_loss: 1.7923 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0101 - accuracy: 0.4296 - val_loss: 1.7956 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0100 - accuracy: 0.4296 - val_loss: 1.7989 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0099 - accuracy: 0.4296 - val_loss: 1.8020 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0099 - accuracy: 0.4296 - val_loss: 1.8052 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/200\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0098 - accuracy: 0.4296 - val_loss: 1.8083 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/200\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0097 - accuracy: 0.4296 - val_loss: 1.8112 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0097 - accuracy: 0.4296 - val_loss: 1.8141 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0096 - accuracy: 0.4296 - val_loss: 1.8168 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0096 - accuracy: 0.4296 - val_loss: 1.8195 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0095 - accuracy: 0.4296 - val_loss: 1.8221 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0095 - accuracy: 0.4296 - val_loss: 1.8246 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0094 - accuracy: 0.4296 - val_loss: 1.8271 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/200\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0094 - accuracy: 0.4296 - val_loss: 1.8295 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0094 - accuracy: 0.4296 - val_loss: 1.8318 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0093 - accuracy: 0.4296 - val_loss: 1.8342 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/200\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0093 - accuracy: 0.4296 - val_loss: 1.8364 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0093 - accuracy: 0.4296 - val_loss: 1.8386 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/200\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1.0092 - accuracy: 0.4296 - val_loss: 1.8407 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0092 - accuracy: 0.4296 - val_loss: 1.8428 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0092 - accuracy: 0.4296 - val_loss: 1.8448 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/200\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0091 - accuracy: 0.4296 - val_loss: 1.8467 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0091 - accuracy: 0.4296 - val_loss: 1.8486 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/200\n",
      "14/14 [==============================] - 0s 16ms/step - loss: 1.0091 - accuracy: 0.4296 - val_loss: 1.8504 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/200\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0091 - accuracy: 0.4296 - val_loss: 1.8523 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0091 - accuracy: 0.4296 - val_loss: 1.8540 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/200\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.8556 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.8571 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/200\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.8587 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.8602 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0090 - accuracy: 0.4296 - val_loss: 1.8618 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/200\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8632 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8647 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8661 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8675 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8687 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/200\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8700 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8712 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8725 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/200\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0089 - accuracy: 0.4296 - val_loss: 1.8736 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/200\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8747 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/200\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8758 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/200\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8770 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8781 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/200\n",
      "14/14 [==============================] - 0s 15ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8791 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8801 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/200\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8810 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/200\n",
      "14/14 [==============================] - 0s 17ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8820 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/200\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8830 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/200\n",
      "14/14 [==============================] - 0s 14ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8840 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/200\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8848 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8857 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8866 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8874 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8881 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.8889 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.8896 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.8904 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.8912 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0088 - accuracy: 0.4296 - val_loss: 1.8919 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.8925 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.8932 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.8938 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.8945 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.8951 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.8955 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.8961 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.8968 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.8974 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.8979 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.8984 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.8990 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.8996 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/200\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9000 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9005 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9009 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9013 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9017 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9022 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9027 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9031 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9035 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/200\n",
      "14/14 [==============================] - 0s 13ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9038 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9042 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9046 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9050 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9053 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9056 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9060 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9062 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9066 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9069 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9072 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9075 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9077 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9080 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9083 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9085 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9087 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9089 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9091 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9094 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9097 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9099 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9101 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9103 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9105 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9107 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9109 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9110 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9112 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9113 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9114 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9115 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9117 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9118 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9120 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9121 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9122 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9124 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9125 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9126 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9128 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9129 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9131 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9132 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9134 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9136 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9138 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9139 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9139 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9139 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9140 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9141 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/200\n",
      "14/14 [==============================] - 0s 11ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9143 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/200\n",
      "14/14 [==============================] - 0s 10ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9144 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/200\n",
      "14/14 [==============================] - 0s 12ms/step - loss: 1.0087 - accuracy: 0.4296 - val_loss: 1.9143 - val_accuracy: 0.0000e+00\n",
      "13/13 [==============================] - 0s 2ms/step - loss: 1.2481 - accuracy: 0.3150\n"
     ]
    }
   ],
   "source": [
    "batch_sizes = [4,8,16,32,64,128] \n",
    "n_epochs= [5, 10 ,20,50,100,200] \n",
    "dict = {}\n",
    "\n",
    "for batch_size in batch_sizes:\n",
    "    dict[batch_size]= {}\n",
    "    for epoch in n_epochs:\n",
    "        model = get_model()\n",
    "        model.compile(optimizer=SGD(learning_rate=0.01), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "        history = model.fit(x, np.array(y), epochs=epoch, validation_split=0.2, shuffle=True, batch_size=batch_size)\n",
    "        eval = model.evaluate(x_test,np.array(y_test))\n",
    "        dict[batch_size][epoch] = [history,eval]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;28mlen\u001b[39m(batch_sizes),\u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m,\u001b[38;5;241m14\u001b[39m))\n\u001b[0;32m      2\u001b[0m fig\u001b[38;5;241m.\u001b[39mtight_layout(pad\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3.5\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, batch_size \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mdict\u001b[39m\u001b[38;5;241m.\u001b[39mkeys()):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(len(batch_sizes),2, figsize=(12,14))\n",
    "fig.tight_layout(pad=3.5)\n",
    "for idx, batch_size in enumerate(dict.keys()):\n",
    "    \n",
    "    keys = list(dict[batch_size].keys())\n",
    "    loss_elements = [value[1][0] for value in dict[batch_size].values()]\n",
    "    accuracy_elements = [value[1][1] for value in dict[batch_size].values()]\n",
    "    ax[idx,0].set_title(f'Batch size {batch_size} ')\n",
    "    ax[idx,0].set_xlabel('Epoch')\n",
    "    ax[idx,0].set_ylabel('Loss')\n",
    "    ax[idx,0].plot(keys, loss_elements, 'r',label='Test Loss')\n",
    "    \n",
    "    ax[idx,1].set_title(f'Batch size {batch_size} ')\n",
    "    ax[idx,1].set_xlabel('Epoch')\n",
    "    ax[idx,1].set_ylabel('Accuracy')\n",
    "    ax[idx,1].plot(keys, accuracy_elements, label='Test Accuracy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [16], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m loss_elements \u001b[38;5;241m=\u001b[39m [value[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdict\u001b[39m[batch_size]\u001b[38;5;241m.\u001b[39mvalues()]\n\u001b[0;32m      5\u001b[0m accuracy_elements \u001b[38;5;241m=\u001b[39m [value[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mdict\u001b[39m[batch_size]\u001b[38;5;241m.\u001b[39mvalues()]\n\u001b[1;32m----> 6\u001b[0m \u001b[43max\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mset_title(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBatch size \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbatch_size\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      7\u001b[0m ax[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_xlabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      8\u001b[0m ax[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mset_ylabel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x1400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,2, figsize=(12,14))\n",
    "fig.tight_layout(pad=3.5)\n",
    "for epoch in n_epochs: \n",
    "    for batch_size in dict.keys():\n",
    "        \n",
    "        loss_elements = dict[batch_size][epoch][1][0]\n",
    "        accuracy_elements = dict[batch_size][epoch][1][1]\n",
    "        if epoch == 5 :\n",
    "            idx = (0,0)   \n",
    "        elif epoch == 10:\n",
    "            idx = (0,1) \n",
    "        elif epoch == 20 :\n",
    "            idx = (1,0)\n",
    "        elif epoch ==50: \n",
    "            idx = (1,1)\n",
    "        elif epoch == 100:\n",
    "            idx = (2,0)\n",
    "        else :\n",
    "            idx = (2,1)\n",
    "\n",
    "\n",
    "        plt.legend()\n",
    "        ax[idx].set_title(f'Batch size {batch_size} ')\n",
    "        ax[idx].set_xlabel('Epoch')\n",
    "        ax[idx].set_ylabel('Loss')\n",
    "        ax[idx].plot(keys, loss_elements, 'r',label='Test Loss')\n",
    "        \n",
    "        ax[idx].set_title(f'Batch size {batch_size} ')\n",
    "        ax[idx].set_xlabel('Epoch')\n",
    "        ax[idx].set_ylabel('Accuracy')\n",
    "        ax[idx].plot(keys, accuracy_elements, label='Test Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1470825672149658, 0.3149999976158142]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict[32][5][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'keys'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [222], line 6\u001b[0m\n\u001b[0;32m      2\u001b[0m data \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      5\u001b[0m textabular \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m|c|c|c|c|\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch_size \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m():\n\u001b[0;32m      7\u001b[0m    \u001b[38;5;28mprint\u001b[39m()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[38;5;124mbegin\u001b[39m\u001b[38;5;132;01m{tabular}\u001b[39;00m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mtextabular\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m}\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'int' object has no attribute 'keys'"
     ]
    }
   ],
   "source": [
    "headers = [\"Batch size\",\"Epochs\",\"LOSS\",\"Accuracy\"]\n",
    "data = {}\n",
    "\n",
    "\n",
    "textabular = f\"|c|c|c|c|\"\n",
    "for batch_size in dict.keys():\n",
    "   print()\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\\\begin{tabular}{\"+textabular+\"}\")\n",
    "print(\"\\\\end{tabular}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [211], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'int' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "dict[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_12 (Conv1D)          (None, 430, 16)           144       \n",
      "                                                                 \n",
      " flatten_8 (Flatten)         (None, 6880)              0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 3)                 20643     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20787 (81.20 KB)\n",
      "Trainable params: 20787 (81.20 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualisation des courbes d'entraînement/validation\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11/11 [==============================] - 0s 2ms/step - loss: 4107.9189 - accuracy: 0.5255\n",
      "Test LOSS : 410791.89%, Test Accuracy : 52.55%\n"
     ]
    }
   ],
   "source": [
    "eval = model.evaluate(x_test,y_test)\n",
    "print(f'Test LOSS : {eval[0]*100:.2f}%, Test Accuracy : {eval[1]*100:.2f}%')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
